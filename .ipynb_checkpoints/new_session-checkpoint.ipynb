{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e7393e7-34e4-49f0-a13f-82c8f3edcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73632491-e618-4e25-9399-1901a326aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 07:37:29,929 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.ui.port','0'). \\\n",
    "    config('spark.sql.warehouse.dir',f\"/user/ubuntu/warehouse\"). \\\n",
    "    config('spark.executor.instances',40). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName('warehouse creator'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e27ec01b-c45d-4ebf-a390-1ecd7972c870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "557ade37-db7c-4ec5-8873-a6c44a0592f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing one of the notebooks from the dataengineerin\n",
    "# spark repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc584aa1-b76e-40c4-9755-2bbeb5fbc058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-26-41.ec2.internal:36331\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>warehouse creator</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fde28dd0ac0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857b1f0b-c50f-40b3-bf5b-17346475b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories\n",
      "customers\n",
      "departments\n",
      "order_items\n",
      "orders\n",
      "products\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "ls /data/retail_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634f888-3ac8-47ca-8cda-c3dfe9da92d2",
   "metadata": {},
   "source": [
    "The path has to be Hadoop file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "760c642a-7b85-427b-8b6a-72f933d51010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders = spark.read.csv('/public/retail_db/orders/',\n",
    "                        schema = \"\"\"\n",
    "                            order_id INT,\n",
    "                            order_date STRING,\n",
    "                            order_customer_id INT,\n",
    "                            order_status STRING\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f398b5-5db9-4e88-8a77-6e4d8551f590",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-21 15:02 /public/retail_db/categories\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-21 15:02 /public/retail_db/customers\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-21 15:03 /public/retail_db/departments\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-21 15:03 /public/retail_db/order_items\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-21 15:03 /public/retail_db/orders\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-21 15:03 /public/retail_db/products\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /public/retail_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b366a39f-28b2-4679-8dc0-f0ecc2132628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------------+---------------+\n",
      "|order_id|          order_date|order_customer_id|   order_status|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "|       1|2013-07-25 00:00:...|            11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:...|              256|PENDING_PAYMENT|\n",
      "+--------+--------------------+-----------------+---------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "orders.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6f1cccd-98be-41e0-9af8-485b5d59e610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-22 13:53 /user/ubuntu/bigg_data/nyse_all\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "hdfs dfs -ls /user/ubuntu/bigg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d108f84c-a3d4-4938-8c7a-26ebb0afe97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ttp://www.nasdaq.com/symbol/zmh|\n",
      "ZB^A|Zions Bancorporation|20.8795|0|n/a|n/a|n/a|n/a|http://www.nasdaq.com/symbol/zb^a|\n",
      "ZB^F|Zions Bancorporation|28.2|0|n/a|n/a|n/a|n/a|http://www.nasdaq.com/symbol/zb^f|\n",
      "ZB^G|Zions Bancorporation|25.66|0|n/a|n/a|n/a|n/a|http://www.nasdaq.com/symbol/zb^g|\n",
      "ZB^H|Zions Bancorporation|23.26|0|n/a|n/a|n/a|n/a|http://www.nasdaq.com/symbol/zb^h|\n",
      "ZBK|Zions Bancorporation|27.0151|0|n/a|n/a|Finance|Major Banks|http://www.nasdaq.com/symbol/zbk|\n",
      "ZOES|Zoe&#39;s Kitchen, Inc.|29.09|535103190.23|n/a|2014|Consumer Services|Restaurants|http://www.nasdaq.com/symbol/zoes|\n",
      "ZTS|Zoetis Inc.|30.72|15391294156.8|n/a|2013|Health Care|Major Pharmaceuticals|http://www.nasdaq.com/symbol/zts|\n",
      "ZA|Zuoan Fashion Limited|1.74|48405108.72|n/a|2011|Consumer Non-Durables|Apparel|http://www.nasdaq.com/symbol/za|\n",
      "ZF|Zweig Fund, Inc. (The)|15.39|318197376.27|n/a|1986|n/a|n/a|http://www.nasdaq.com/symbol/zf|\n",
      "ZTR|Zweig Total Return Fund, Inc. (The)|14.15|490203176.1|n/a|1988|n/a|n/a|http://www.nasdaq.com/symbol/ztr|\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "hdfs dfs -tail /user/ubuntu/bigg_data/nyse_all/nyse_stocks/companylist_noheader.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fba380dc-77a7-4b6d-899a-7ebe4560be4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse_read = spark.read.csv(\"/user/ubuntu/bigg_data/nyse_all/nyse_stocks/\",\n",
    "                          sep='|',inferSchema=True)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cea8f8cc-f49e-4328-bbb5-ca2b8f25d869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: double (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      " |-- _c5: string (nullable = true)\n",
      " |-- _c6: string (nullable = true)\n",
      " |-- _c7: string (nullable = true)\n",
      " |-- _c8: string (nullable = true)\n",
      " |-- _c9: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nyse_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54fe311c-696a-49c1-9e75-03ed7c7ebc93",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 07:38:38,404 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:38,405 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:38,995 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:39,015 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:39,041 WARN metastore.HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:39,082 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:39,083 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:39,169 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:39,182 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:39,201 ERROR metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 1 of 10) with error: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "\n",
      "2023-01-23 07:38:41,238 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:41,239 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:41,281 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:41,283 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:41,289 WARN metastore.HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:41,329 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:41,330 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:41,377 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:41,390 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:41,398 ERROR metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 2 of 10) with error: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "\n",
      "2023-01-23 07:38:43,431 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:43,432 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:43,475 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:43,483 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:43,491 WARN metastore.HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:43,523 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:43,523 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:43,567 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:43,575 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:43,580 ERROR metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 3 of 10) with error: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "\n",
      "2023-01-23 07:38:45,686 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:45,686 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:45,716 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:45,726 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:45,730 WARN metastore.HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:45,761 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:45,761 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:45,791 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:45,799 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:45,807 ERROR metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 4 of 10) with error: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "\n",
      "2023-01-23 07:38:47,837 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:47,838 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:47,872 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:47,877 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:47,881 WARN metastore.HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:47,911 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:47,914 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:47,944 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:47,947 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:47,963 ERROR metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 5 of 10) with error: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "\n",
      "2023-01-23 07:38:49,991 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:49,991 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:50,020 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:50,025 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:50,037 WARN metastore.HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:50,066 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:50,067 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:50,094 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:50,098 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:50,110 ERROR metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 6 of 10) with error: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "\n",
      "2023-01-23 07:38:52,142 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:52,142 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:52,202 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:52,207 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:52,214 WARN metastore.HiveMetaStore: Retrying creating default database after error: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:655)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:52,242 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:52,242 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:52,275 ERROR Datastore.Schema: Failed initialising database.\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:52,280 ERROR DataNucleus.Datastore: Exception thrown creating StoreManager. See the nested exception\n",
      "Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "org.datanucleus.exceptions.NucleusDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:498)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\t... 117 more\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "Nested Throwables StackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "2023-01-23 07:38:52,283 ERROR metastore.RetryingHMSHandler: Retrying HMSHandler after 2000 ms (attempt 7 of 10) with error: javax.jdo.JDOFatalDataStoreException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:529)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:830)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "NestedThrowablesStackTrace:\n",
      "java.sql.SQLException: Unable to open a test connection to the given database. JDBC url = jdbc:postgresql://localhost:6432/metastore, username = hive. Terminating connection pool (set lazyInit to true if you expect to start your database after your app). Original Exception: ------\n",
      "org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "------\n",
      "\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat com.jolbox.bonecp.PoolUtil.generateSQLException(PoolUtil.java:192)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:422)\n",
      "\tat com.jolbox.bonecp.BoneCPDataSource.getConnection(BoneCPDataSource.java:120)\n",
      "\tat org.datanucleus.store.rdbms.ConnectionFactoryImpl$ManagedConnectionImpl.getConnection(ConnectionFactoryImpl.java:483)\n",
      "\tat org.datanucleus.store.rdbms.RDBMSStoreManager.<init>(RDBMSStoreManager.java:297)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.datanucleus.plugin.NonManagedPluginRegistry.createExecutableExtension(NonManagedPluginRegistry.java:606)\n",
      "\tat org.datanucleus.plugin.PluginManager.createExecutableExtension(PluginManager.java:301)\n",
      "\tat org.datanucleus.NucleusContextHelper.createStoreManagerForProperties(NucleusContextHelper.java:133)\n",
      "\tat org.datanucleus.PersistenceNucleusContextImpl.initialise(PersistenceNucleusContextImpl.java:422)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.freezeConfiguration(JDOPersistenceManagerFactory.java:817)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.createPersistenceManagerFactory(JDOPersistenceManagerFactory.java:334)\n",
      "\tat org.datanucleus.api.jdo.JDOPersistenceManagerFactory.getPersistenceManagerFactory(JDOPersistenceManagerFactory.java:213)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat javax.jdo.JDOHelper$16.run(JDOHelper.java:1975)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.jdo.JDOHelper.invoke(JDOHelper.java:1970)\n",
      "\tat javax.jdo.JDOHelper.invokeGetPersistenceManagerFactoryOnImplementation(JDOHelper.java:1177)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:814)\n",
      "\tat javax.jdo.JDOHelper.getPersistenceManagerFactory(JDOHelper.java:702)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPMF(ObjectStore.java:521)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.getPersistenceManager(ObjectStore.java:550)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initializeHelper(ObjectStore.java:405)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.initialize(ObjectStore.java:342)\n",
      "\tat org.apache.hadoop.hive.metastore.ObjectStore.setConf(ObjectStore.java:303)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:77)\n",
      "\tat org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:137)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.<init>(RawStoreProxy.java:58)\n",
      "\tat org.apache.hadoop.hive.metastore.RawStoreProxy.getProxy(RawStoreProxy.java:67)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newRawStoreForConf(HiveMetaStore.java:628)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMSForConf(HiveMetaStore.java:594)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.getMS(HiveMetaStore.java:588)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.createDefaultDB(HiveMetaStore.java:659)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.init(HiveMetaStore.java:431)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:148)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:107)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.<init>(RetryingHMSHandler.java:79)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingHMSHandler.getProxy(RetryingHMSHandler.java:92)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStore.newRetryingHMSHandler(HiveMetaStore.java:6902)\n",
      "\tat org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.SessionHiveMetaStoreClient.<init>(SessionHiveMetaStoreClient.java:70)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "\tat org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1707)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133)\n",
      "\tat org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:3600)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3652)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:3632)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getAllFunctions(Hive.java:3894)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.reloadFunctions(Hive.java:248)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.registerAllFunctionsOnce(Hive.java:231)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.<init>(Hive.java:388)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.create(Hive.java:332)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.getInternal(Hive.java:312)\n",
      "\tat org.apache.hadoop.hive.ql.metadata.Hive.get(Hive.java:288)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.client(HiveClientImpl.scala:257)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.$anonfun$withHiveState$1(HiveClientImpl.scala:283)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.liftedTree1$1(HiveClientImpl.scala:224)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.retryLocked(HiveClientImpl.scala:223)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.withHiveState(HiveClientImpl.scala:273)\n",
      "\tat org.apache.spark.sql.hive.client.HiveClientImpl.databaseExists(HiveClientImpl.scala:384)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.$anonfun$databaseExists$1(HiveExternalCatalog.scala:224)\n",
      "\tat scala.runtime.java8.JFunction0$mcZ$sp.apply(JFunction0$mcZ$sp.java:23)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.withClient(HiveExternalCatalog.scala:102)\n",
      "\tat org.apache.spark.sql.hive.HiveExternalCatalog.databaseExists(HiveExternalCatalog.scala:224)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:134)\n",
      "\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:124)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager$lzycompute(SharedState.scala:154)\n",
      "\tat org.apache.spark.sql.internal.SharedState.globalTempViewManager(SharedState.scala:152)\n",
      "\tat org.apache.spark.sql.hive.HiveSessionStateBuilder.$anonfun$catalog$2(HiveSessionStateBuilder.scala:60)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager$lzycompute(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.globalTempViewManager(SessionCatalog.scala:99)\n",
      "\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.setCurrentDatabase(SessionCatalog.scala:281)\n",
      "\tat org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:104)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:40)\n",
      "\tat org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:46)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$logicalPlan$1(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n",
      "\tat org.apache.spark.sql.Dataset.<init>(Dataset.scala:228)\n",
      "\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96)\n",
      "\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:618)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:613)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.postgresql.util.PSQLException: Connection to localhost:6432 refused. Check that the hostname and port are correct and that the postmaster is accepting TCP/IP connections.\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:303)\n",
      "\tat org.postgresql.core.ConnectionFactory.openConnection(ConnectionFactory.java:51)\n",
      "\tat org.postgresql.jdbc.PgConnection.<init>(PgConnection.java:223)\n",
      "\tat org.postgresql.Driver.makeConnection(Driver.java:465)\n",
      "\tat org.postgresql.Driver.connect(Driver.java:264)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:664)\n",
      "\tat java.sql.DriverManager.getConnection(DriverManager.java:208)\n",
      "\tat com.jolbox.bonecp.BoneCP.obtainRawInternalConnection(BoneCP.java:361)\n",
      "\tat com.jolbox.bonecp.BoneCP.<init>(BoneCP.java:416)\n",
      "\t... 119 more\n",
      "Caused by: java.net.ConnectException: Connection refused (Connection refused)\n",
      "\tat java.net.PlainSocketImpl.socketConnect(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)\n",
      "\tat java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)\n",
      "\tat java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)\n",
      "\tat java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)\n",
      "\tat java.net.Socket.connect(Socket.java:607)\n",
      "\tat org.postgresql.core.PGStream.createSocket(PGStream.java:231)\n",
      "\tat org.postgresql.core.PGStream.<init>(PGStream.java:95)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.tryConnect(ConnectionFactoryImpl.java:98)\n",
      "\tat org.postgresql.core.v3.ConnectionFactoryImpl.openConnectionImpl(ConnectionFactoryImpl.java:213)\n",
      "\t... 127 more\n",
      "\n",
      "2023-01-23 07:38:54,316 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:38:54,317 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-01-23 07:38:56,014 ERROR metastore.ObjectStore: Version information found in metastore differs 1.2.0 from expected schema version 2.3.0. Schema verififcation is disabled hive.metastore.schema.verification\n",
      "2023-01-23 07:38:56,015 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore ubuntu@172.31.26.41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 07:38:56,267 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE practice_retail\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c2ea81-e0bb-4166-a673-f437bf1f6bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>database</th><th>tableName</th><th>isTemporary</th></tr>\n",
       "<tr><td>practice_retail</td><td>order_items</td><td>false</td></tr>\n",
       "<tr><td>practice_retail</td><td>orders</td><td>false</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---------------+-----------+-----------+\n",
       "|       database|  tableName|isTemporary|\n",
       "+---------------+-----------+-----------+\n",
       "|practice_retail|order_items|      false|\n",
       "|practice_retail|     orders|      false|\n",
       "+---------------+-----------+-----------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0822416e-97f6-4ca1-bb62-9ebfb0af47cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d637225-ce57-439e-ac94-f32c6fc2be8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>database</th><th>tableName</th><th>isTemporary</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+---------+-----------+\n",
       "|database|tableName|isTemporary|\n",
       "+--------+---------+-----------+\n",
       "+--------+---------+-----------+"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbc3f447-fc7c-4055-b4d2-1e6be012c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -put /home/ubuntu/bigdata/yelp_academic_dataset_user.json \\\n",
    "    /user/ubuntu/bigg_data/yelp_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e4afc83a-4dc4-493d-bc2d-1dddcf3aed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\n",
      "-rw-r--r--   1 ubuntu supergroup 2951073792 2023-01-23 06:11 /user/ubuntu/bigg_data/yelp_data/yelp_academic_dataset_user.json\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/ubuntu/bigg_data/yelp_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ca75d44-d570-4be6-986c-9b3fd6d96f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "yelping = spark.read.json(\"/user/ubuntu/bigg_data/yelp_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e74264a-075e-412f-9aa2-479ad345a068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 items\n",
      "-rw-r--r--   1 ubuntu supergroup  792609318 2023-01-23 06:30 /user/ubuntu/bigg_data/airline/2009.csv\n",
      "-rw-r--r--   1 ubuntu supergroup  794152224 2023-01-23 06:30 /user/ubuntu/bigg_data/airline/2010.csv\n",
      "-rw-r--r--   1 ubuntu supergroup  746858940 2023-01-23 06:30 /user/ubuntu/bigg_data/airline/2011.csv\n",
      "-rw-r--r--   1 ubuntu supergroup  775286574 2023-01-23 06:30 /user/ubuntu/bigg_data/airline/2012.csv\n",
      "-rw-r--r--   1 ubuntu supergroup  121307136 2023-01-23 06:30 /user/ubuntu/bigg_data/airline/2013.csv\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls /user/ubuntu/bigg_data/airline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf637f96-c17b-46f2-a135-8e1751abf971",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 07:41:45,150 WARN util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|2009-01-01|        XE|             1204|   DCA| EWR|        1100|  1058.0|     -2.0|    18.0|    1116.0|   1158.0|    8.0|        1202|  1206.0|      4.0|      0.0|             null|     0.0|            62.0|               68.0|    42.0|   199.0|         null|         null|     null|          null|               null|       null|\n",
      "|2009-01-01|        XE|             1206|   EWR| IAD|        1510|  1509.0|     -1.0|    28.0|    1537.0|   1620.0|    4.0|        1632|  1624.0|     -8.0|      0.0|             null|     0.0|            82.0|               75.0|    43.0|   213.0|         null|         null|     null|          null|               null|       null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline = spark.read.csv(\"/user/ubuntu/bigg_data/airline/2009.csv\",\n",
    "                         sep=',',inferSchema=True,header=True)\n",
    "airline.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e84c0a5b-aecc-40d6-8f5d-80853aa1825a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6429338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airline.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ab48f9-027f-4044-b468-18394556b2e2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- WHEELS_OFF: double (nullable = true)\n",
      " |-- WHEELS_ON: double (nullable = true)\n",
      " |-- TAXI_IN: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      " |-- ARR_TIME: double (nullable = true)\n",
      " |-- ARR_DELAY: double (nullable = true)\n",
      " |-- CANCELLED: double (nullable = true)\n",
      " |-- CANCELLATION_CODE: string (nullable = true)\n",
      " |-- DIVERTED: double (nullable = true)\n",
      " |-- CRS_ELAPSED_TIME: double (nullable = true)\n",
      " |-- ACTUAL_ELAPSED_TIME: double (nullable = true)\n",
      " |-- AIR_TIME: double (nullable = true)\n",
      " |-- DISTANCE: double (nullable = true)\n",
      " |-- CARRIER_DELAY: double (nullable = true)\n",
      " |-- WEATHER_DELAY: double (nullable = true)\n",
      " |-- NAS_DELAY: double (nullable = true)\n",
      " |-- SECURITY_DELAY: double (nullable = true)\n",
      " |-- LATE_AIRCRAFT_DELAY: double (nullable = true)\n",
      " |-- Unnamed: 27: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airline_schema = airline.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c9b164b-264b-4ef6-8de3-7c44db2e0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlineSchema = airline.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f42728cb-9915-4188-a8a6-ce5d33175436",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_airline = spark.read.csv(\"/user/ubuntu/bigg_data/airline/\",\n",
    "                              schema=airlineSchema,\n",
    "                              header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "459b23f5-0637-4442-a9f4-026683bfffdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26028000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_airline.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c1fa19-3b84-4be4-9cca-0012fdd616c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|Unnamed: 27|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "|2009-01-01|        XE|             1204|   DCA| EWR|        1100|  1058.0|     -2.0|    18.0|    1116.0|   1158.0|    8.0|        1202|  1206.0|      4.0|      0.0|             null|     0.0|            62.0|               68.0|    42.0|   199.0|         null|         null|     null|          null|               null|       null|\n",
      "|2009-01-01|        XE|             1206|   EWR| IAD|        1510|  1509.0|     -1.0|    28.0|    1537.0|   1620.0|    4.0|        1632|  1624.0|     -8.0|      0.0|             null|     0.0|            82.0|               75.0|    43.0|   213.0|         null|         null|     null|          null|               null|       null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_airline.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2103f448-da15-47c2-93a5-0071ac32a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "636b0093-7192-4c63-991e-94949057e8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_airline = full_airline.drop('Unnamed: 27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f3c60c5-1616-4342-ab40-7008dc267798",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_schema = full_airline.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd3a7f0-7d33-4cf8-b3dd-ddba666e2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 07:02:30,484 WARN metastore.ObjectStore: Failed to get database airline_demo, returning NoSuchObjectException\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE airline_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df553a85-ec6c-4980-bdb8-8ed4cbbde83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase('airline_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a09a6b22-3a37-4d4a-9044-5aaea5bda3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Database(name='airline_demo', description='', locationUri='hdfs://localhost:9000/user/ubuntu/warehouse/airline_demo.db'),\n",
       " Database(name='default', description='Default Hive database', locationUri='hdfs://localhost:9000/user/hive/warehouse'),\n",
       " Database(name='practice_retail', description='', locationUri='hdfs://localhost:9000/user/ubuntu/warehouse/practice_retail.db')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd26b91-60cc-4add-b811-c9f55c6be67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\",\"12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdf71420-d05d-435a-ba06-e89e0acf0af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 07:13:18,281 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "2023-01-23 07:13:18,568 WARN conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "2023-01-23 07:13:18,568 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:13:18,568 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "full_airline.write.saveAsTable('full_airline',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79156f52-e686-475a-8a72-f057ab6a86f0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 items\n",
      "-rw-r--r--   1 ubuntu supergroup          0 2023-01-23 07:13 /user/ubuntu/warehouse/airline_demo.db/full_airline/_SUCCESS\n",
      "-rw-r--r--   1 ubuntu supergroup     23.3 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00000-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.3 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00001-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.3 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00002-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.4 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00003-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.1 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00004-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.5 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00005-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.3 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00006-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.4 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00007-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.5 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00008-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.2 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00009-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.6 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00010-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.5 M 2023-01-23 07:11 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00011-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.6 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00012-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.6 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00013-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     23.2 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00014-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     19.8 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00015-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     19.8 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00016-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     19.9 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00017-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     20.1 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00018-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     19.9 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00019-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     21.5 M 2023-01-23 07:12 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00020-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     21.0 M 2023-01-23 07:13 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00021-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     21.3 M 2023-01-23 07:13 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00022-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     15.5 M 2023-01-23 07:13 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00023-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n",
      "-rw-r--r--   1 ubuntu supergroup     13.1 M 2023-01-23 07:13 /user/ubuntu/warehouse/airline_demo.db/full_airline/part-00024-252ee949-904f-476f-bced-994be24cf212-c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "hdfs dfs -ls -h /user/ubuntu/warehouse/airline_demo.db/full_airline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea74817-3471-447e-8e1b-0ed90b03c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 07:43:18,558 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "2023-01-23 07:43:18,615 WARN conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "2023-01-23 07:43:18,615 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-01-23 07:43:18,616 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>FL_DATE</th><th>OP_CARRIER</th><th>OP_CARRIER_FL_NUM</th><th>ORIGIN</th><th>DEST</th><th>CRS_DEP_TIME</th><th>DEP_TIME</th><th>DEP_DELAY</th><th>TAXI_OUT</th><th>WHEELS_OFF</th><th>WHEELS_ON</th><th>TAXI_IN</th><th>CRS_ARR_TIME</th><th>ARR_TIME</th><th>ARR_DELAY</th><th>CANCELLED</th><th>CANCELLATION_CODE</th><th>DIVERTED</th><th>CRS_ELAPSED_TIME</th><th>ACTUAL_ELAPSED_TIME</th><th>AIR_TIME</th><th>DISTANCE</th><th>CARRIER_DELAY</th><th>WEATHER_DELAY</th><th>NAS_DELAY</th><th>SECURITY_DELAY</th><th>LATE_AIRCRAFT_DELAY</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
       "|FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|\n",
       "+-------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
       "+-------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.createTable('copy_airline',schema=new_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16357063-89c8-4685-9f47-54d33bee34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(\"airline_demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cc57e05-6c92-457a-b2c0-e8680ca12335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='full_airline', database='airline_demo', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c81a631b-0c85-4e63-b9d6-1d76bff3dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:======================================>                   (4 + 2) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|WHEELS_OFF|WHEELS_ON|TAXI_IN|CRS_ARR_TIME|ARR_TIME|ARR_DELAY|CANCELLED|CANCELLATION_CODE|DIVERTED|CRS_ELAPSED_TIME|ACTUAL_ELAPSED_TIME|AIR_TIME|DISTANCE|CARRIER_DELAY|WEATHER_DELAY|NAS_DELAY|SECURITY_DELAY|LATE_AIRCRAFT_DELAY|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "|2009-01-01|        XE|             1204|   DCA| EWR|        1100|  1058.0|     -2.0|    18.0|    1116.0|   1158.0|    8.0|        1202|  1206.0|      4.0|      0.0|             null|     0.0|            62.0|               68.0|    42.0|   199.0|         null|         null|     null|          null|               null|\n",
      "|2009-01-01|        XE|             1206|   EWR| IAD|        1510|  1509.0|     -1.0|    28.0|    1537.0|   1620.0|    4.0|        1632|  1624.0|     -8.0|      0.0|             null|     0.0|            82.0|               75.0|    43.0|   213.0|         null|         null|     null|          null|               null|\n",
      "|2009-01-01|        XE|             1207|   EWR| DCA|        1100|  1059.0|     -1.0|    20.0|    1119.0|   1155.0|    6.0|        1210|  1201.0|     -9.0|      0.0|             null|     0.0|            70.0|               62.0|    36.0|   199.0|         null|         null|     null|          null|               null|\n",
      "|2009-01-01|        XE|             1208|   DCA| EWR|        1240|  1249.0|      9.0|    10.0|    1259.0|   1336.0|    9.0|        1357|  1345.0|    -12.0|      0.0|             null|     0.0|            77.0|               56.0|    37.0|   199.0|         null|         null|     null|          null|               null|\n",
      "|2009-01-01|        XE|             1209|   IAD| EWR|        1715|  1705.0|    -10.0|    24.0|    1729.0|   1809.0|   13.0|        1900|  1822.0|    -38.0|      0.0|             null|     0.0|           105.0|               77.0|    40.0|   213.0|         null|         null|     null|          null|               null|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+----------+---------+-------+------------+--------+---------+---------+-----------------+--------+----------------+-------------------+--------+--------+-------------+-------------+---------+--------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM full_airline LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c137cd2b-af01-4809-a9c1-ae25a0f42601",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_airline = spark.sql(\"\"\"SELECT DATE_FORMAT(FL_DATE,'yyyy-MM') as month_year,\n",
    "              FL_DATE, OP_CARRIER, OP_CARRIER_FL_NUM,ORIGIN, DEST, CRS_DEP_TIME,\n",
    "              DEP_TIME,DEP_DELAY,TAXI_OUT,CRS_ARR_TIME\n",
    "          FROM full_airline\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ce52086-9523-4daa-95b6-5f3614fca13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|distinct_month|\n",
      "+--------------+\n",
      "|       2010-03|\n",
      "|       2012-05|\n",
      "|       2012-06|\n",
      "|       2010-07|\n",
      "|       2011-01|\n",
      "|       2011-02|\n",
      "|       2011-05|\n",
      "|       2012-01|\n",
      "|       2011-12|\n",
      "|       2013-01|\n",
      "|       2013-02|\n",
      "|       2009-12|\n",
      "|       2012-07|\n",
      "|       2009-04|\n",
      "|       2012-08|\n",
      "|       2010-09|\n",
      "|       2012-04|\n",
      "|       2010-05|\n",
      "|       2012-09|\n",
      "|       2009-08|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DISTINCT(DATE_FORMAT(FL_DATE,'yyyy-MM')) as distinct_month\n",
    "                FROM full_airline\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28dae77a-d78f-40cf-a9f7-6d6c80e3bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DISTINCT(DATE_FORMAT(FL_DATE,'yyyy-MM')) as distinct_month\n",
    "                FROM full_airline\"\"\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "706ae1a4-d418-4b1f-89d7-ce39deab1f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "month_airline.repartition(49,'month_year').write. \\\n",
    "    mode('overwrite'). \\\n",
    "    partitionBy('month_year'). \\\n",
    "    format('parquet'). \\\n",
    "    save('/user/ubuntu/airline_part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29d8bfe1-27cf-40fa-b321-4edc017589c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_year: string (nullable = true)\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "month_airline.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9398623c-0370-477d-8d16-791db8807ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "/dev/root        25G   20G  4.5G  82% /\n",
      "tmpfs           3.9G     0  3.9G   0% /dev/shm\n",
      "tmpfs           1.6G  1.0M  1.6G   1% /run\n",
      "tmpfs           5.0M     0  5.0M   0% /run/lock\n",
      "/dev/xvda15     105M  5.3M  100M   5% /boot/efi\n",
      "tmpfs           795M  4.0K  795M   1% /run/user/1000\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5f6f9c9-5795-4423-9de5-2b31cfed730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "month_airline.repartition(49,'month_year').write. \\\n",
    "    mode('overwrite'). \\\n",
    "    partitionBy('month_year'). \\\n",
    "    format('csv'). \\\n",
    "    save('/user/ubuntu/airline_part_csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4a14352-ea84-4c51-b6e8-073cf608594f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 items\n",
      "-rw-r--r--   1 ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/_SUCCESS\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-01\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-02\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-03\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-04\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2009-05\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2009-06\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-07\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-08\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-09\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-11\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-12\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-01\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-02\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-03\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-04\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-05\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-06\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-07\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-08\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-09\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-10\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-11\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-12\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-01\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-02\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-03\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-04\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-05\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-06\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-08\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-09\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-10\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-11\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-12\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-01\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-02\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-03\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-04\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-05\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-06\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-07\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-08\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-09\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-10\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-11\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-12\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2013-01\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2013-02\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2013-03\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "\n",
    "hdfs dfs -ls /user/ubuntu/airline_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94710270-c1a4-4b67-b87e-6d32dffe0ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(\"practice_retail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "357e20d0-3dec-42ab-aba1-75f562836725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 items\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:37 /user/ubuntu/.sparkStaging\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 08:08 /user/ubuntu/airline_part_csv\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 06:30 /user/ubuntu/bigg_data\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-22 07:38 /user/ubuntu/retail_db\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:02 /user/ubuntu/warehouse\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls -h /user/ubuntu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "551eeeb0-ec73-4eac-b6a3-07cff1df4415",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 08:19:34,215 ERROR client.TransportClient: Failed to send RPC RPC 9005628966120757684 to /172.31.26.41:45552: java.nio.channels.ClosedChannelException\n",
      "java.nio.channels.ClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "2023-01-23 08:19:34,251 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 3 at RPC address 172.31.26.41:55770, but got no response. Marking as agent lost.\n",
      "java.io.IOException: Failed to send RPC RPC 9005628966120757684 to /172.31.26.41:45552: java.nio.channels.ClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:363)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:340)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:993)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.nio.channels.ClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n",
      "\t... 12 more\n",
      "2023-01-23 08:19:34,270 ERROR client.TransportClient: Failed to send RPC RPC 8384501936122497963 to /172.31.26.41:45552: java.nio.channels.ClosedChannelException\n",
      "java.nio.channels.ClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "2023-01-23 08:19:34,270 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 2 at RPC address 172.31.26.41:55760, but got no response. Marking as agent lost.\n",
      "java.io.IOException: Failed to send RPC RPC 8384501936122497963 to /172.31.26.41:45552: java.nio.channels.ClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:363)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:340)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:993)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.nio.channels.ClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n",
      "\t... 12 more\n",
      "2023-01-23 08:19:34,270 ERROR client.TransportClient: Failed to send RPC RPC 8921980734566430206 to /172.31.26.41:45552: java.nio.channels.ClosedChannelException\n",
      "java.nio.channels.ClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "2023-01-23 08:19:34,271 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Attempted to get executor loss reason for executor id 1 at RPC address 172.31.26.41:55738, but got no response. Marking as agent lost.\n",
      "java.io.IOException: Failed to send RPC RPC 8921980734566430206 to /172.31.26.41:45552: java.nio.channels.ClosedChannelException\n",
      "\tat org.apache.spark.network.client.TransportClient$RpcChannelListener.handleFailure(TransportClient.java:363)\n",
      "\tat org.apache.spark.network.client.TransportClient$StdChannelListener.operationComplete(TransportClient.java:340)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListener0(DefaultPromise.java:577)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListenersNow(DefaultPromise.java:551)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.notifyListeners(DefaultPromise.java:490)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setValue0(DefaultPromise.java:615)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.setFailure0(DefaultPromise.java:608)\n",
      "\tat io.netty.util.concurrent.DefaultPromise.tryFailure(DefaultPromise.java:117)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.safeSetFailure(AbstractChannel.java:993)\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.write(AbstractChannel.java:865)\n",
      "\tat io.netty.channel.DefaultChannelPipeline$HeadContext.write(DefaultChannelPipeline.java:1367)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWrite0(AbstractChannelHandlerContext.java:717)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext.invokeWriteAndFlush(AbstractChannelHandlerContext.java:764)\n",
      "\tat io.netty.channel.AbstractChannelHandlerContext$WriteTask.run(AbstractChannelHandlerContext.java:1071)\n",
      "\tat io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:472)\n",
      "\tat io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:500)\n",
      "\tat io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)\n",
      "\tat io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.nio.channels.ClosedChannelException\n",
      "\tat io.netty.channel.AbstractChannel$AbstractUnsafe.newClosedChannelException(AbstractChannel.java:957)\n",
      "\t... 12 more\n",
      "2023-01-23 08:19:34,281 ERROR cluster.YarnScheduler: Lost executor 3 on ip-172-31-26-41.ec2.internal: Executor Process Lost\n",
      "2023-01-23 08:19:34,289 ERROR cluster.YarnScheduler: Lost executor 2 on ip-172-31-26-41.ec2.internal: Executor Process Lost\n",
      "2023-01-23 08:19:34,301 ERROR cluster.YarnScheduler: Lost executor 1 on ip-172-31-26-41.ec2.internal: Executor Process Lost\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -get /user/ubuntu/airline_part_csv /home/ubuntu/bigdata/airline_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db9bbd13-5900-47c2-903d-05e9ad917636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLE IF EXISTS airline_partition\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23101e6d-318f-4c02-a3d3-8df46563ecfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 08:28:33,984 WARN metastore.HiveMetaStore: Location: hdfs://localhost:9000/user/ubuntu/warehouse/practice_retail.db/airline_partition specified for non-external table:airline_partition\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"CREATE TABLE IF NOT EXISTS airline_partition(\n",
    "                FL_DATE string,\n",
    "                OP_CARRIER string,\n",
    "                OP_CARRIER_FL_NUM integer,\n",
    "                ORIGIN string,\n",
    "                DEST string,\n",
    "                CRS_DEP_TIME integer,\n",
    "                DEP_TIME double,\n",
    "                DEP_DELAY double,\n",
    "                TAXI_OUT double,\n",
    "                CRS_ARR_TIME integer) PARTITIONED BY (month_year string)\n",
    "        ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a48a6901-186b-4bc0-9ecf-0c2708d8d04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>col_name</th><th>data_type</th><th>comment</th></tr>\n",
       "<tr><td>FL_DATE</td><td>string</td><td>null</td></tr>\n",
       "<tr><td>OP_CARRIER</td><td>string</td><td>null</td></tr>\n",
       "<tr><td>OP_CARRIER_FL_NUM</td><td>int</td><td>null</td></tr>\n",
       "<tr><td>ORIGIN</td><td>string</td><td>null</td></tr>\n",
       "<tr><td>DEST</td><td>string</td><td>null</td></tr>\n",
       "<tr><td>CRS_DEP_TIME</td><td>int</td><td>null</td></tr>\n",
       "<tr><td>DEP_TIME</td><td>double</td><td>null</td></tr>\n",
       "<tr><td>DEP_DELAY</td><td>double</td><td>null</td></tr>\n",
       "<tr><td>TAXI_OUT</td><td>double</td><td>null</td></tr>\n",
       "<tr><td>CRS_ARR_TIME</td><td>int</td><td>null</td></tr>\n",
       "<tr><td>month_year</td><td>string</td><td>null</td></tr>\n",
       "<tr><td># Partition Infor...</td><td></td><td></td></tr>\n",
       "<tr><td># col_name</td><td>data_type</td><td>comment</td></tr>\n",
       "<tr><td>month_year</td><td>string</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+---------+-------+\n",
       "|            col_name|data_type|comment|\n",
       "+--------------------+---------+-------+\n",
       "|             FL_DATE|   string|   null|\n",
       "|          OP_CARRIER|   string|   null|\n",
       "|   OP_CARRIER_FL_NUM|      int|   null|\n",
       "|              ORIGIN|   string|   null|\n",
       "|                DEST|   string|   null|\n",
       "|        CRS_DEP_TIME|      int|   null|\n",
       "|            DEP_TIME|   double|   null|\n",
       "|           DEP_DELAY|   double|   null|\n",
       "|            TAXI_OUT|   double|   null|\n",
       "|        CRS_ARR_TIME|      int|   null|\n",
       "|          month_year|   string|   null|\n",
       "|# Partition Infor...|         |       |\n",
       "|          # col_name|data_type|comment|\n",
       "|          month_year|   string|   null|\n",
       "+--------------------+---------+-------+"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DESCRIBE airline_partition\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec1c9227-11cc-46a5-ba4e-fa8feb1b8a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"TRUNCATE TABLE airline_partition\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c4be81-36a1-4699-80bf-f73a3d75da17",
   "metadata": {},
   "source": [
    "## If the load data is executed without the partition specification\n",
    "the command will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cdb9bddf-3fe9-49c5-97fb-e24194668010",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "LOAD DATA target table `practice_retail`.`airline_partition` is partitioned, but no partition spec is provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mLOAD DATA LOCAL INPATH \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/bigdata/airline_csv/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m                INTO TABLE airline_partition\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: LOAD DATA target table `practice_retail`.`airline_partition` is partitioned, but no partition spec is provided"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"LOAD DATA LOCAL INPATH '/home/ubuntu/bigdata/airline_csv/' \n",
    "                INTO TABLE airline_partition\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9888d54-f56e-4fd3-a233-b2885dddd809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"ALTER TABLE airline_partition ADD PARTITION (month_year='2010-02')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8e28d39-ed87-4d89-9d0e-48d35a6e60dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"ALTER TABLE airline_partition \n",
    "                    ADD PARTITION (month_year='2010-07')\n",
    "                    PARTITION (month_year='2010-03')\n",
    "                    PARTITION (month_year='2010-04')\n",
    "                    PARTITION (month_year='2010-05')\n",
    "                    PARTITION (month_year='2010-06')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a2172a2-4613-44f0-9d73-cf67aced6fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 08:36:27,549 WARN hive.log: Updating partition stats fast for: airline_partition\n",
      "2023-01-23 08:36:27,551 WARN hive.log: Updated size to 25182498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"LOAD DATA LOCAL INPATH '/home/ubuntu/bigdata/airline_csv/month_year=2010-02'\n",
    "                    INTO TABLE airline_partition PARTITION (month_year='2010-02')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a977a27-665f-4044-850d-5590e546df6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "|FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|CRS_ARR_TIME|month_year|\n",
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM airline_partition\n",
    "                WHERE month_year='2010-03'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "29ca50d6-081d-4209-a81e-cc48de117c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 08:37:59,773 WARN hive.log: Updating partition stats fast for: airline_partition\n",
      "2023-01-23 08:37:59,776 WARN hive.log: Updated size to 28763689\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"LOAD DATA LOCAL INPATH '/home/ubuntu/bigdata/airline_csv/month_year=2010-03'\n",
    "                    INTO TABLE airline_partition PARTITION (month_year='2010-03')\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "324df95c-104d-49fd-9659-22863c30ff05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|CRS_ARR_TIME|month_year|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "|2010-03-06|        AA|             1378|   DFW| HSV|         930|  1003.0|     33.0|     8.0|        1110|   2010-03|\n",
      "|2010-03-06|        AA|             1378|   ELP| DFW|         600|   557.0|     -3.0|    10.0|         840|   2010-03|\n",
      "|2010-03-06|        AA|             1380|   COS| DFW|        1220|  1224.0|      4.0|    19.0|        1505|   2010-03|\n",
      "|2010-03-06|        AA|             1380|   DFW| IND|        1555|  1555.0|      0.0|    10.0|        1855|   2010-03|\n",
      "|2010-03-06|        AA|             1381|   MSP| ORD|        1725|  1720.0|     -5.0|    19.0|        1900|   2010-03|\n",
      "|2010-03-06|        AA|             1381|   ORD| SEA|        1950|  1947.0|     -3.0|    20.0|        2215|   2010-03|\n",
      "|2010-03-06|        AA|             1382|   MIA| EWR|        2120|  2118.0|     -2.0|    13.0|          20|   2010-03|\n",
      "|2010-03-06|        AA|             1387|   BNA| DFW|        1705|  1746.0|     41.0|    11.0|        1915|   2010-03|\n",
      "|2010-03-06|        AA|             1389|   ICT| DFW|        1145|  1137.0|     -8.0|    12.0|        1305|   2010-03|\n",
      "|2010-03-06|        AA|             1390|   LAX| ORD|        1040|  1033.0|     -7.0|    15.0|        1630|   2010-03|\n",
      "|2010-03-06|        AA|             1392|   DFW| SAT|        2040|  2038.0|     -2.0|    12.0|        2145|   2010-03|\n",
      "|2010-03-06|        AA|             1392|   ICT| DFW|        1810|  1757.0|    -13.0|    13.0|        1935|   2010-03|\n",
      "|2010-03-06|        AA|             1394|   DFW| FLL|         845|   857.0|     12.0|    12.0|        1225|   2010-03|\n",
      "|2010-03-06|        AA|             1394|   MCI| DFW|         605|   555.0|    -10.0|    10.0|         750|   2010-03|\n",
      "|2010-03-06|        AA|             1397|   ORD| MCO|        1515|  1514.0|     -1.0|    15.0|        1850|   2010-03|\n",
      "|2010-03-06|        AA|             1398|   DFW| MIA|        1700|  1701.0|      1.0|    18.0|        2040|   2010-03|\n",
      "|2010-03-06|        AA|             1398|   STL| DFW|        1355|  1352.0|     -3.0|    10.0|        1545|   2010-03|\n",
      "|2010-03-06|        AA|             1400|   MIA| JFK|        1935|  1935.0|      0.0|    27.0|        2229|   2010-03|\n",
      "|2010-03-06|        AA|             1403|   ORD| RSW|         615|   621.0|      6.0|    10.0|        1000|   2010-03|\n",
      "|2010-03-06|        AA|             1404|   DFW| IAH|        1250|  1246.0|     -4.0|    12.0|        1400|   2010-03|\n",
      "+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM airline_partition\n",
    "                WHERE month_year='2010-03'\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0e82adb-1859-4f30-af67-5cf9e9ab8a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"TRUNCATE TABLE airline_partition\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b1d63c3c-60fb-495e-ade8-528c743e1b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Table(name='airline_partition', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='copy_airline', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='order_items', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='orders', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e17797b7-1ca4-4b3e-87cf-65e3e5c301d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase('airline_demo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "27dd0c54-8b7a-4592-9ce1-b8bf33d17b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='full_airline', database='airline_demo', description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "068a6862-2bf2-4925-9ca8-97899301bb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+\n",
      "|month_year|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|CRS_ARR_TIME|\n",
      "+----------+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+\n",
      "|   2011-06|2011-06-14|        XE|             6074|   DEN| SDF|        1758|  1804.0|      6.0|    15.0|        2234|\n",
      "|   2011-06|2011-06-14|        XE|             6075|   MCI| ORD|         546|   531.0|    -15.0|    10.0|         710|\n",
      "+----------+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DATE_FORMAT(FL_DATE,'yyyy-MM') as month_year,\n",
    "              FL_DATE, OP_CARRIER, OP_CARRIER_FL_NUM,ORIGIN, DEST, CRS_DEP_TIME,\n",
    "              DEP_TIME,DEP_DELAY,TAXI_OUT,CRS_ARR_TIME\n",
    "          FROM full_airline\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0866a4e4-8a65-40ee-9013-3802015ffb45",
   "metadata": {},
   "source": [
    "The below command fails with a parsing error. Need to use a different \n",
    "type of equation..Or use the dynamic partition method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69d59c0a-4dbd-432d-9735-f4f6abf5dd09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\nmismatched input 'LIKE' expecting {')', ','}(line 1, pos 74)\n\n== SQL ==\nINSERT INTO TABLE practice_retail.airline_partition PARTITION (month_year LIKE '20%')\n--------------------------------------------------------------------------^^^\n            SELECT DATE_FORMAT(FL_DATE,'yyyy-MM') as month_year,\n              FL_DATE, OP_CARRIER, OP_CARRIER_FL_NUM,ORIGIN, DEST, CRS_DEP_TIME,\n              DEP_TIME,DEP_DELAY,TAXI_OUT,CRS_ARR_TIME\n          FROM full_airline\n            WHERE month_year LIKE '20%'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO TABLE practice_retail.airline_partition PARTITION (month_year LIKE \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m20\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m            SELECT DATE_FORMAT(FL_DATE,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myyyy-MM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m) as month_year,\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m              FL_DATE, OP_CARRIER, OP_CARRIER_FL_NUM,ORIGIN, DEST, CRS_DEP_TIME,\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m              DEP_TIME,DEP_DELAY,TAXI_OUT,CRS_ARR_TIME\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;43m          FROM full_airline\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;43m            WHERE month_year LIKE \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m20\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \nmismatched input 'LIKE' expecting {')', ','}(line 1, pos 74)\n\n== SQL ==\nINSERT INTO TABLE practice_retail.airline_partition PARTITION (month_year LIKE '20%')\n--------------------------------------------------------------------------^^^\n            SELECT DATE_FORMAT(FL_DATE,'yyyy-MM') as month_year,\n              FL_DATE, OP_CARRIER, OP_CARRIER_FL_NUM,ORIGIN, DEST, CRS_DEP_TIME,\n              DEP_TIME,DEP_DELAY,TAXI_OUT,CRS_ARR_TIME\n          FROM full_airline\n            WHERE month_year LIKE '20%'\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"INSERT INTO TABLE practice_retail.airline_partition PARTITION (month_year LIKE '20%')\n",
    "            SELECT DATE_FORMAT(FL_DATE,'yyyy-MM') as month_year,\n",
    "              FL_DATE, OP_CARRIER, OP_CARRIER_FL_NUM,ORIGIN, DEST, CRS_DEP_TIME,\n",
    "              DEP_TIME,DEP_DELAY,TAXI_OUT,CRS_ARR_TIME\n",
    "          FROM full_airline\n",
    "            WHERE month_year LIKE '20%'\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7060682c-8020-41bf-9dc2-7087271a7360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                 key|      value|\n",
      "+--------------------+-----------+\n",
      "|hive.exec.dynamic...|<undefined>|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SET hive.exec.dynamic.partition\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b8d9a80-af2c-4bb5-af89-96a7a6b68f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|                 key|      value|\n",
      "+--------------------+-----------+\n",
      "|hive.exec.dynamic...|<undefined>|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SET hive.exec.dynamic.partition.mode\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2ebd3ea9-c506-468a-a2c5-7013aa7decb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|                 key|    value|\n",
      "+--------------------+---------+\n",
      "|spark.hadoop.hive...|nonstrict|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SET spark.hadoop.hive.exec.dynamic.partition.mode=nonstrict\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "899cea11-105e-4803-84e9-ea03c7fa0701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>key</th><th>value</th></tr>\n",
       "<tr><td>spark.hadoop.hive...</td><td>true</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-----+\n",
       "|                 key|value|\n",
       "+--------------------+-----+\n",
       "|spark.hadoop.hive...| true|\n",
       "+--------------------+-----+"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"SET spark.hadoop.hive.exec.dynamic.partition=true\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2160f44a-aaec-477e-bf6b-58bbeb8002e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(\"practice_retail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab9693b9-552c-4934-a090-28ed2bd9fe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"SELECT DATE_FORMAT(FL_DATE,'yyyy-MM') as month_year,\n",
    "              FL_DATE, OP_CARRIER, OP_CARRIER_FL_NUM,ORIGIN, DEST, CRS_DEP_TIME,\n",
    "              DEP_TIME,DEP_DELAY,TAXI_OUT,CRS_ARR_TIME\n",
    "          FROM airline_demo.full_airline\"\"\").createTempView(\"month_airline_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76a5fd05-f982-4a34-a5d6-6f3e6d5af421",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+\n",
      "|month_year|   FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|CRS_ARR_TIME|\n",
      "+----------+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+\n",
      "|   2011-06|2011-06-14|        XE|             6074|   DEN| SDF|        1758|  1804.0|      6.0|    15.0|        2234|\n",
      "|   2011-06|2011-06-14|        XE|             6075|   MCI| ORD|         546|   531.0|    -15.0|    10.0|         710|\n",
      "+----------+----------+----------+-----------------+------+----+------------+--------+---------+--------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM month_airline_view\"\"\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ddf224a4-29a8-443c-be67-43fa39898eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- month_year: string (nullable = true)\n",
      " |-- FL_DATE: string (nullable = true)\n",
      " |-- OP_CARRIER: string (nullable = true)\n",
      " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
      " |-- ORIGIN: string (nullable = true)\n",
      " |-- DEST: string (nullable = true)\n",
      " |-- CRS_DEP_TIME: integer (nullable = true)\n",
      " |-- DEP_TIME: double (nullable = true)\n",
      " |-- DEP_DELAY: double (nullable = true)\n",
      " |-- TAXI_OUT: double (nullable = true)\n",
      " |-- CRS_ARR_TIME: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT * FROM month_airline_view\"\"\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e993d061-dd79-48bf-a2dc-992c66992603",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_airline_partition_schema = spark.sql(\"\"\"SELECT * FROM month_airline_view\"\"\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f51f177-8ff4-40b7-95cf-eade4fc53698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(month_year,StringType,true),StructField(FL_DATE,StringType,true),StructField(OP_CARRIER,StringType,true),StructField(OP_CARRIER_FL_NUM,IntegerType,true),StructField(ORIGIN,StringType,true),StructField(DEST,StringType,true),StructField(CRS_DEP_TIME,IntegerType,true),StructField(DEP_TIME,DoubleType,true),StructField(DEP_DELAY,DoubleType,true),StructField(TAXI_OUT,DoubleType,true),StructField(CRS_ARR_TIME,IntegerType,true)))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_airline_partition_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "722483b2-876f-460a-ba1e-a7ff27360ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'practice_retail'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac36e716-2cb3-4b61-8a8f-f32369be3062",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot write incompatible data to table '`practice_retail`.`airline_partition`':\n- Cannot safely cast 'OP_CARRIER_FL_NUM': string to int\n- Cannot safely cast 'CRS_DEP_TIME': string to int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO TABLE airline_partition PARTITION (month_year)\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m            SELECT * FROM month_airline_view\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot write incompatible data to table '`practice_retail`.`airline_partition`':\n- Cannot safely cast 'OP_CARRIER_FL_NUM': string to int\n- Cannot safely cast 'CRS_DEP_TIME': string to int"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"INSERT INTO TABLE airline_partition PARTITION (month_year)\n",
    "            SELECT * FROM month_airline_view\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f928a072-2f2d-4dd8-9054-2d413fd2ed9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--   1 ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/_SUCCESS\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-01\n",
      "-rw-r--r--   1 ubuntu supergroup    5271632 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-01/part-00039-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-02\n",
      "-rw-r--r--   1 ubuntu supergroup    4808792 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-02/part-00027-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-03\n",
      "-rw-r--r--   1 ubuntu supergroup    5512942 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-03/part-00016-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-04\n",
      "-rw-r--r--   1 ubuntu supergroup    5354265 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-04/part-00014-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2009-05\n",
      "-rw-r--r--   1 ubuntu supergroup    5396982 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2009-05/part-00006-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2009-06\n",
      "-rw-r--r--   1 ubuntu supergroup    5558532 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2009-06/part-00000-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-07\n",
      "-rw-r--r--   1 ubuntu supergroup    5766792 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-07/part-00018-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-08\n",
      "-rw-r--r--   1 ubuntu supergroup    5661076 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-08/part-00015-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-09\n",
      "-rw-r--r--   1 ubuntu supergroup   10128925 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-09/part-00021-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-11\n",
      "-rw-r--r--   1 ubuntu supergroup    5010581 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-11/part-00015-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-12\n",
      "-rw-r--r--   1 ubuntu supergroup    5255521 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2009-12/part-00029-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-01\n",
      "-rw-r--r--   1 ubuntu supergroup    5212071 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-01/part-00003-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-02\n",
      "-rw-r--r--   1 ubuntu supergroup    4776442 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-02/part-00022-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-03\n",
      "-rw-r--r--   1 ubuntu supergroup    5463534 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-03/part-00048-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-04\n",
      "-rw-r--r--   1 ubuntu supergroup    5225380 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-04/part-00031-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-05\n",
      "-rw-r--r--   1 ubuntu supergroup    5404482 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-05/part-00048-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-06\n",
      "-rw-r--r--   1 ubuntu supergroup    5506792 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-06/part-00041-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-07\n",
      "-rw-r--r--   1 ubuntu supergroup    5690363 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-07/part-00037-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-08\n",
      "-rw-r--r--   1 ubuntu supergroup    5666649 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-08/part-00000-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-09\n",
      "-rw-r--r--   1 ubuntu supergroup    5180378 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-09/part-00042-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2010-10\n",
      "-rw-r--r--   1 ubuntu supergroup    5390096 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-10/part-00009-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-11\n",
      "-rw-r--r--   1 ubuntu supergroup    5143548 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-11/part-00022-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-12\n",
      "-rw-r--r--   1 ubuntu supergroup    5398321 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2010-12/part-00040-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-01\n",
      "-rw-r--r--   1 ubuntu supergroup    4924413 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-01/part-00033-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-02\n",
      "-rw-r--r--   1 ubuntu supergroup    4525246 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-02/part-00030-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-03\n",
      "-rw-r--r--   1 ubuntu supergroup    5246412 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-03/part-00003-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-04\n",
      "-rw-r--r--   1 ubuntu supergroup    5069804 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-04/part-00004-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-05\n",
      "-rw-r--r--   1 ubuntu supergroup    5215943 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-05/part-00001-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-06\n",
      "-rw-r--r--   1 ubuntu supergroup   10700141 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-06/part-00014-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-08\n",
      "-rw-r--r--   1 ubuntu supergroup    5428343 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-08/part-00019-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-09\n",
      "-rw-r--r--   1 ubuntu supergroup    4876241 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-09/part-00004-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-10\n",
      "-rw-r--r--   1 ubuntu supergroup    5025133 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-10/part-00009-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-11\n",
      "-rw-r--r--   1 ubuntu supergroup    4752759 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2011-11/part-00033-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-12\n",
      "-rw-r--r--   1 ubuntu supergroup    4937777 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2011-12/part-00003-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-01\n",
      "-rw-r--r--   1 ubuntu supergroup    3487373 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-01/part-00012-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-02\n",
      "-rw-r--r--   1 ubuntu supergroup    3328730 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-02/part-00018-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-03\n",
      "-rw-r--r--   1 ubuntu supergroup    3787319 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-03/part-00000-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-04\n",
      "-rw-r--r--   1 ubuntu supergroup    3625253 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-04/part-00025-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-05\n",
      "-rw-r--r--   1 ubuntu supergroup    3755112 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-05/part-00026-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-06\n",
      "-rw-r--r--   1 ubuntu supergroup    3851813 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-06/part-00012-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-07\n",
      "-rw-r--r--   1 ubuntu supergroup    4002209 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-07/part-00014-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-08\n",
      "-rw-r--r--   1 ubuntu supergroup    3956491 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-08/part-00042-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-09\n",
      "-rw-r--r--   1 ubuntu supergroup    3602214 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-09/part-00007-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-10\n",
      "-rw-r--r--   1 ubuntu supergroup    3727541 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-10/part-00033-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-11\n",
      "-rw-r--r--   1 ubuntu supergroup    3543745 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2012-11/part-00043-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-12\n",
      "-rw-r--r--   1 ubuntu supergroup    3603725 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2012-12/part-00002-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2013-01\n",
      "-rw-r--r--   1 ubuntu supergroup    5128922 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2013-01/part-00048-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:56 /user/ubuntu/airline_part/month_year=2013-02\n",
      "-rw-r--r--   1 ubuntu supergroup    4735851 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2013-02/part-00008-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n",
      "drwxr-xr-x   - ubuntu supergroup          0 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2013-03\n",
      "-rw-r--r--   1 ubuntu supergroup      75560 2023-01-23 07:57 /user/ubuntu/airline_part/month_year=2013-03/part-00012-edfe942b-41ab-4d09-89eb-ea664d6557fa.c000.snappy.parquet\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "hdfs dfs -ls -R /user/ubuntu/airline_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "53bd513a-94e8-41cc-bdcc-c98cbabad37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLE airline_part\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "173add12-db6e-43be-adbe-8efedc38aed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>FL_DATE</th><th>OP_CARRIER</th><th>OP_CARRIER_FL_NUM</th><th>ORIGIN</th><th>DEST</th><th>CRS_DEP_TIME</th><th>DEP_TIME</th><th>DEP_DELAY</th><th>TAXI_OUT</th><th>CRS_ARR_TIME</th><th>month_year</th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
       "|FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|CRS_ARR_TIME|month_year|\n",
       "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
       "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.createTable('airline_part',\n",
    "                          path='/user/ubuntu/airline_part',\n",
    "                          source='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "53f3a7f2-1d72-43c1-8f69-51e9027b5d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'practice_retail'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.currentDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a3a5f19-ad7f-4180-86a4-fd35a1a9e191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='airline_part', database='practice_retail', description=None, tableType='EXTERNAL', isTemporary=False),\n",
       " Table(name='airline_partition', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='copy_airline', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='order_items', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='orders', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='month_airline_view', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3727adc7-6cc0-48b4-858c-f5da9ac95652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "|FL_DATE|OP_CARRIER|OP_CARRIER_FL_NUM|ORIGIN|DEST|CRS_DEP_TIME|DEP_TIME|DEP_DELAY|TAXI_OUT|CRS_ARR_TIME|month_year|\n",
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "+-------+----------+-----------------+------+----+------------+--------+---------+--------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.table('airline_part').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b0c4f17a-d8a4-4146-9c7d-5eedecae3de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|partition|\n",
      "+---------+\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SHOW PARTITIONS airline_part\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "899a8878-f283-4660-9bb3-2917ad0252db",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.recoverPartitions('airline_part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5c748b43-5e98-4674-9cbf-528ca95c4bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         partition|\n",
      "+------------------+\n",
      "|month_year=2009-01|\n",
      "|month_year=2009-02|\n",
      "|month_year=2009-03|\n",
      "|month_year=2009-04|\n",
      "|month_year=2009-05|\n",
      "|month_year=2009-06|\n",
      "|month_year=2009-07|\n",
      "|month_year=2009-08|\n",
      "|month_year=2009-09|\n",
      "|month_year=2009-11|\n",
      "|month_year=2009-12|\n",
      "|month_year=2010-01|\n",
      "|month_year=2010-02|\n",
      "|month_year=2010-03|\n",
      "|month_year=2010-04|\n",
      "|month_year=2010-05|\n",
      "|month_year=2010-06|\n",
      "|month_year=2010-07|\n",
      "|month_year=2010-08|\n",
      "|month_year=2010-09|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SHOW PARTITIONS airline_part\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7f74ffde-064b-41b7-a790-930c02429c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         partition|\n",
      "+------------------+\n",
      "|month_year=2010-02|\n",
      "|month_year=2010-03|\n",
      "|month_year=2010-04|\n",
      "|month_year=2010-05|\n",
      "|month_year=2010-06|\n",
      "|month_year=2010-07|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SHOW PARTITIONS airline_partition\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aae35d46-33a4-4dcf-8b5b-59370e599448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th></th></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "++\n",
       "||\n",
       "++\n",
       "++"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLE airline_part\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "349d1b78-20a4-4d3f-8659-43f1b9892c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Database(name='airline_demo', description='', locationUri='hdfs://localhost:9000/user/ubuntu/warehouse/airline_demo.db'),\n",
       " Database(name='default', description='Default Hive database', locationUri='hdfs://localhost:9000/user/hive/warehouse'),\n",
       " Database(name='practice_retail', description='', locationUri='hdfs://localhost:9000/user/ubuntu/warehouse/practice_retail.db')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listDatabases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "97905a1f-5518-4602-8404-9f8c3ad51c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='airline_partition', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='copy_airline', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='order_items', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='orders', database='practice_retail', description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='month_airline_view', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4b3886d4-173d-42b5-bc96-bc5565958d51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\nno viable alternative at input 'DROP TABLES'(line 1, pos 5)\n\n== SQL ==\nDROP TABLES airline_partition copy_airline order_items orders month_airline_view\n-----^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mDROP TABLES airline_partition copy_airline order_items orders month_airline_view\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/session.py:723\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msql\u001b[39m(\u001b[38;5;28mself\u001b[39m, sqlQuery):\n\u001b[1;32m    708\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a :class:`DataFrame` representing the result of the given query.\u001b[39;00m\n\u001b[1;32m    709\u001b[0m \n\u001b[1;32m    710\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 2.0.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;124;03m    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\u001b[39;00m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqlQuery\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\n",
      "File \u001b[0;32m/opt/spark3/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/spark3/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \nno viable alternative at input 'DROP TABLES'(line 1, pos 5)\n\n== SQL ==\nDROP TABLES airline_partition copy_airline order_items orders month_airline_view\n-----^^^\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLES airline_partition copy_airline order_items orders month_airline_view\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
