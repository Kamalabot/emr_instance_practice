{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install pyspark","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-30T08:58:13.337277Z","iopub.execute_input":"2023-03-30T08:58:13.338254Z","iopub.status.idle":"2023-03-30T08:58:49.599263Z","shell.execute_reply.started":"2023-03-30T08:58:13.338213Z","shell.execute_reply":"2023-03-30T08:58:49.597634Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting py4j==0.10.9.5\n  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=87c0f744609fb94bfe3a8c9ba9637ef439ef15d399689d033a8d2439dd64b9b0\n  Stored in directory: /root/.cache/pip/wheels/5a/54/9b/a89cac960efb57c4c35d41cc7c9f7b80daa21108bc376339b7\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\n  Attempting uninstall: py4j\n    Found existing installation: py4j 0.10.9.7\n    Uninstalling py4j-0.10.9.7:\n      Successfully uninstalled py4j-0.10.9.7\nSuccessfully installed py4j-0.10.9.5 pyspark-3.3.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Background of the ETL\n\nThe note book will run inside the spark cluster, with Pyspark3 instance. Here ETL steps are created, and tested before executing in the cluster.\n\nThis notebook is dealing with the Customer data, which is available in CSV format. The dataset is attached with this notebook, no need download the data when testing in kaggle environment.\n\nWhen executing inside the cluster the dataset needs to be pulled using kaggle api command, which is explained in the below videos\n\nhttps://youtu.be/m_4ZDaX24co","metadata":{}},{"cell_type":"code","source":"### Do not execute this cell... This is for example\n\nspark = SparkSession. \\\n    builder. \\\n    config('spark.ui.port', '0'). \\\n    config(\"spark.sql.warehouse.dir\", f\"/user/{username}/warehouse\"). \\\n    enableHiveSupport(). \\\n    appName(f'{username} | ETL - Overview'). \\\n    master('yarn'). \\\n    getOrCreate()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\n\nspark = SparkSession. \\\n    builder.appName('Data Loader'). \\\n    enableHiveSupport(). \\\n    master('local'). \\\n    getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:07:32.097468Z","iopub.execute_input":"2023-03-30T09:07:32.097849Z","iopub.status.idle":"2023-03-30T09:07:36.148968Z","shell.execute_reply.started":"2023-03-30T09:07:32.097814Z","shell.execute_reply":"2023-03-30T09:07:36.148089Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"23/03/30 09:07:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reading the file into spark context\n\ncustomer_raw = spark.read.csv(\"/kaggle/input/customers-dataset/Customers.csv\",\n                              header=True,\n                             inferSchema=True)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:10:47.778752Z","iopub.execute_input":"2023-03-30T09:10:47.779129Z","iopub.status.idle":"2023-03-30T09:10:52.003566Z","shell.execute_reply.started":"2023-03-30T09:10:47.779098Z","shell.execute_reply":"2023-03-30T09:10:52.002776Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# What transformations are executed in this notebook\n\n1) The column names are modified in the Spark Dataframe\n\n2) New table under the name customer_spark_table is created in Spark metastore\n\n3) Execute a simple filter transformation. Select the rows that have income above 15000, and spending power above 50 \n\n4) Write a new table inside spark metastore\n\n5) Write the new table as csv file \n\n6) Convert the Jupyter notebook cells into Pyspark Script that can execute code on the given csv file(it will customer.csv file only)\n\n","metadata":{}},{"cell_type":"code","source":"customer_raw.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:11:07.978576Z","iopub.execute_input":"2023-03-30T09:11:07.978983Z","iopub.status.idle":"2023-03-30T09:11:08.196320Z","shell.execute_reply.started":"2023-03-30T09:11:07.978945Z","shell.execute_reply":"2023-03-30T09:11:08.195376Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[Row(CustomerID=1, Gender='Male', Age=19, Annual Income ($)=15000, Spending Score (1-100)=39, Profession='Healthcare', Work Experience=1, Family Size=4),\n Row(CustomerID=2, Gender='Male', Age=21, Annual Income ($)=35000, Spending Score (1-100)=81, Profession='Engineer', Work Experience=3, Family Size=3)]"},"metadata":{}}]},{"cell_type":"code","source":"customer_raw.show(2,truncate=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:11:34.299401Z","iopub.execute_input":"2023-03-30T09:11:34.299783Z","iopub.status.idle":"2023-03-30T09:11:34.463715Z","shell.execute_reply.started":"2023-03-30T09:11:34.299747Z","shell.execute_reply":"2023-03-30T09:11:34.462742Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"+----------+------+---+-----------------+----------------------+----------+---------------+-----------+\n|CustomerID|Gender|Age|Annual Income ($)|Spending Score (1-100)|Profession|Work Experience|Family Size|\n+----------+------+---+-----------------+----------------------+----------+---------------+-----------+\n|1         |Male  |19 |15000            |39                    |Healthcare|1              |4          |\n|2         |Male  |21 |35000            |81                    |Engineer  |3              |3          |\n+----------+------+---+-----------------+----------------------+----------+---------------+-----------+\nonly showing top 2 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"customer_raw.columns","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:11:55.542927Z","iopub.execute_input":"2023-03-30T09:11:55.543330Z","iopub.status.idle":"2023-03-30T09:11:55.550878Z","shell.execute_reply.started":"2023-03-30T09:11:55.543296Z","shell.execute_reply":"2023-03-30T09:11:55.549801Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['CustomerID',\n 'Gender',\n 'Age',\n 'Annual Income ($)',\n 'Spending Score (1-100)',\n 'Profession',\n 'Work Experience',\n 'Family Size']"},"metadata":{}}]},{"cell_type":"code","source":"customer_raw.schema","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:15:12.337157Z","iopub.execute_input":"2023-03-30T09:15:12.337524Z","iopub.status.idle":"2023-03-30T09:15:12.344321Z","shell.execute_reply.started":"2023-03-30T09:15:12.337495Z","shell.execute_reply":"2023-03-30T09:15:12.343428Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"StructType([StructField('CustomerID', IntegerType(), True), StructField('Gender', StringType(), True), StructField('Age', IntegerType(), True), StructField('Annual Income ($)', IntegerType(), True), StructField('Spending Score (1-100)', IntegerType(), True), StructField('Profession', StringType(), True), StructField('Work Experience', IntegerType(), True), StructField('Family Size', IntegerType(), True)])"},"metadata":{}}]},{"cell_type":"code","source":"from pyspark.sql.types import StructField, StructType, IntegerType,StringType\n\nupdated_schema = StructType([StructField('CustomerID', \n                                         IntegerType(), True), \n                             StructField('Gender', \n                                         StringType(), True), \n                             StructField('Age', \n                                         IntegerType(), True), \n                             StructField('AnnualIncome', \n                                         IntegerType(), True), \n                             StructField('SpendingScore', \n                                         IntegerType(), True), \n                             StructField('Profession', \n                                         StringType(), True), \n                             StructField('WorkExperience', \n                                         IntegerType(), True), \n                             StructField('FamilySize', \n                                         IntegerType(), True)])","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:20:30.768099Z","iopub.execute_input":"2023-03-30T09:20:30.768512Z","iopub.status.idle":"2023-03-30T09:20:30.775977Z","shell.execute_reply.started":"2023-03-30T09:20:30.768477Z","shell.execute_reply":"2023-03-30T09:20:30.774770Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Re-reading with the schema \n\ncustomer_updated = spark.read.csv(\"/kaggle/input/customers-dataset/Customers.csv\",\n                                 header=True, schema=updated_schema)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:21:26.727559Z","iopub.execute_input":"2023-03-30T09:21:26.727953Z","iopub.status.idle":"2023-03-30T09:21:26.776714Z","shell.execute_reply.started":"2023-03-30T09:21:26.727919Z","shell.execute_reply":"2023-03-30T09:21:26.775755Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"customer_updated.show(2)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:21:41.616078Z","iopub.execute_input":"2023-03-30T09:21:41.616468Z","iopub.status.idle":"2023-03-30T09:21:41.759734Z","shell.execute_reply.started":"2023-03-30T09:21:41.616434Z","shell.execute_reply":"2023-03-30T09:21:41.758721Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"23/03/30 09:21:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: CustomerID, Gender, Age, Annual Income ($), Spending Score (1-100), Profession, Work Experience, Family Size\n Schema: CustomerID, Gender, Age, AnnualIncome, SpendingScore, Profession, WorkExperience, FamilySize\nExpected: AnnualIncome but found: Annual Income ($)\nCSV file: file:///kaggle/input/customers-dataset/Customers.csv\n+----------+------+---+------------+-------------+----------+--------------+----------+\n|CustomerID|Gender|Age|AnnualIncome|SpendingScore|Profession|WorkExperience|FamilySize|\n+----------+------+---+------------+-------------+----------+--------------+----------+\n|         1|  Male| 19|       15000|           39|Healthcare|             1|         4|\n|         2|  Male| 21|       35000|           81|  Engineer|             3|         3|\n+----------+------+---+------------+-------------+----------+--------------+----------+\nonly showing top 2 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"customer_updated.printSchema()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:22:40.224486Z","iopub.execute_input":"2023-03-30T09:22:40.224886Z","iopub.status.idle":"2023-03-30T09:22:40.233198Z","shell.execute_reply.started":"2023-03-30T09:22:40.224852Z","shell.execute_reply":"2023-03-30T09:22:40.231635Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"root\n |-- CustomerID: integer (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Age: integer (nullable = true)\n |-- AnnualIncome: integer (nullable = true)\n |-- SpendingScore: integer (nullable = true)\n |-- Profession: string (nullable = true)\n |-- WorkExperience: integer (nullable = true)\n |-- FamilySize: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"spark.sql(\"Show Databases\").show()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:25:05.566639Z","iopub.execute_input":"2023-03-30T09:25:05.567039Z","iopub.status.idle":"2023-03-30T09:25:05.635490Z","shell.execute_reply.started":"2023-03-30T09:25:05.567005Z","shell.execute_reply":"2023-03-30T09:25:05.634582Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"+---------+\n|namespace|\n+---------+\n|  default|\n+---------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"spark.sql(\"CREATE DATABASE IF NOT EXISTS customer_spark_db\")","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:25:40.456105Z","iopub.execute_input":"2023-03-30T09:25:40.456507Z","iopub.status.idle":"2023-03-30T09:25:40.646373Z","shell.execute_reply.started":"2023-03-30T09:25:40.456473Z","shell.execute_reply":"2023-03-30T09:25:40.645100Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"23/03/30 09:25:40 WARN ObjectStore: Failed to get database customer_spark_db, returning NoSuchObjectException\n23/03/30 09:25:40 WARN ObjectStore: Failed to get database customer_spark_db, returning NoSuchObjectException\n23/03/30 09:25:40 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n23/03/30 09:25:40 WARN ObjectStore: Failed to get database customer_spark_db, returning NoSuchObjectException\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"DataFrame[]"},"metadata":{}}]},{"cell_type":"code","source":"spark.sql(\"USE customer_spark_db\")","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:25:59.264001Z","iopub.execute_input":"2023-03-30T09:25:59.264333Z","iopub.status.idle":"2023-03-30T09:25:59.288418Z","shell.execute_reply.started":"2023-03-30T09:25:59.264303Z","shell.execute_reply":"2023-03-30T09:25:59.287336Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DataFrame[]"},"metadata":{}}]},{"cell_type":"code","source":"customer_updated.write.saveAsTable(\"customer_spark_table\",\n                                  mode=\"overwrite\",\n                                  format=\"csv\")","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:29:30.697951Z","iopub.execute_input":"2023-03-30T09:29:30.698289Z","iopub.status.idle":"2023-03-30T09:29:31.660741Z","shell.execute_reply.started":"2023-03-30T09:29:30.698262Z","shell.execute_reply":"2023-03-30T09:29:31.659311Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"23/03/30 09:29:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n Header: CustomerID, Gender, Age, Annual Income ($), Spending Score (1-100), Profession, Work Experience, Family Size\n Schema: CustomerID, Gender, Age, AnnualIncome, SpendingScore, Profession, WorkExperience, FamilySize\nExpected: AnnualIncome but found: Annual Income ($)\nCSV file: file:///kaggle/input/customers-dataset/Customers.csv\n23/03/30 09:29:31 WARN HiveExternalCatalog: Couldn't find corresponding Hive SerDe for data source provider csv. Persisting data source table `customer_spark_db`.`customer_spark_table` into Hive metastore in Spark SQL specific format, which is NOT compatible with Hive.\n23/03/30 09:29:31 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n23/03/30 09:29:31 WARN HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n23/03/30 09:29:31 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n23/03/30 09:29:31 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n","output_type":"stream"}]},{"cell_type":"code","source":"spark.sql(\"SHOW TABLES\").show()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:29:53.150868Z","iopub.execute_input":"2023-03-30T09:29:53.151669Z","iopub.status.idle":"2023-03-30T09:29:53.358300Z","shell.execute_reply.started":"2023-03-30T09:29:53.151612Z","shell.execute_reply":"2023-03-30T09:29:53.357329Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"+-----------------+--------------------+-----------+\n|        namespace|           tableName|isTemporary|\n+-----------------+--------------------+-----------+\n|customer_spark_db|customer_spark_table|      false|\n+-----------------+--------------------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"spark.sql(\"\"\"SELECT * FROM customer_spark_table LIMIT 5\"\"\").show()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:31:12.023401Z","iopub.execute_input":"2023-03-30T09:31:12.023814Z","iopub.status.idle":"2023-03-30T09:31:12.747601Z","shell.execute_reply.started":"2023-03-30T09:31:12.023780Z","shell.execute_reply":"2023-03-30T09:31:12.746693Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"+----------+------+---+------------+-------------+-------------+--------------+----------+\n|CustomerID|Gender|Age|AnnualIncome|SpendingScore|   Profession|WorkExperience|FamilySize|\n+----------+------+---+------------+-------------+-------------+--------------+----------+\n|         1|  Male| 19|       15000|           39|   Healthcare|             1|         4|\n|         2|  Male| 21|       35000|           81|     Engineer|             3|         3|\n|         3|Female| 20|       86000|            6|     Engineer|             1|         1|\n|         4|Female| 23|       59000|           77|       Lawyer|             0|         2|\n|         5|Female| 31|       38000|           40|Entertainment|             2|         6|\n+----------+------+---+------------+-------------+-------------+--------------+----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"spark.sql(\"\"\"SELECT * FROM customer_spark_table\n            WHERE AnnualIncome > 15000 AND\n            SpendingScore > 50\"\"\").show(5)","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:34:36.944177Z","iopub.execute_input":"2023-03-30T09:34:36.944557Z","iopub.status.idle":"2023-03-30T09:34:37.404075Z","shell.execute_reply.started":"2023-03-30T09:34:36.944523Z","shell.execute_reply":"2023-03-30T09:34:37.403133Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"+----------+------+---+------------+-------------+----------+--------------+----------+\n|CustomerID|Gender|Age|AnnualIncome|SpendingScore|Profession|WorkExperience|FamilySize|\n+----------+------+---+------------+-------------+----------+--------------+----------+\n|         2|  Male| 21|       35000|           81|  Engineer|             3|         3|\n|         4|Female| 23|       59000|           77|    Lawyer|             0|         2|\n|         6|Female| 22|       58000|           76|    Artist|             0|         2|\n|         8|Female| 23|       84000|           94|Healthcare|             1|         3|\n|        10|Female| 30|       98000|           72|    Artist|             1|         4|\n+----------+------+---+------------+-------------+----------+--------------+----------+\nonly showing top 5 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"spark.sql(\"\"\"SELECT * FROM customer_spark_table\n            WHERE AnnualIncome > 15000 AND\n            SpendingScore > 50\"\"\").count()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:34:52.567151Z","iopub.execute_input":"2023-03-30T09:34:52.567533Z","iopub.status.idle":"2023-03-30T09:34:52.917849Z","shell.execute_reply.started":"2023-03-30T09:34:52.567499Z","shell.execute_reply":"2023-03-30T09:34:52.916962Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"972"},"metadata":{}}]},{"cell_type":"code","source":"spark.sql(\"\"\"CREATE TABLE transformed_customer_table\n            SELECT * FROM customer_spark_table\n            WHERE AnnualIncome > 15000 AND\n            SpendingScore > 50\"\"\")","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:35:57.097205Z","iopub.execute_input":"2023-03-30T09:35:57.097593Z","iopub.status.idle":"2023-03-30T09:35:57.794246Z","shell.execute_reply.started":"2023-03-30T09:35:57.097556Z","shell.execute_reply":"2023-03-30T09:35:57.793313Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"23/03/30 09:35:57 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.\n23/03/30 09:35:57 WARN HiveMetaStore: Location: file:/kaggle/working/spark-warehouse/customer_spark_db.db/transformed_customer_table specified for non-external table:transformed_customer_table\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"DataFrame[]"},"metadata":{}}]},{"cell_type":"code","source":"spark.sql(\"SELECT * FROM transformed_customer_table\").count()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:36:23.663557Z","iopub.execute_input":"2023-03-30T09:36:23.664736Z","iopub.status.idle":"2023-03-30T09:36:23.941235Z","shell.execute_reply.started":"2023-03-30T09:36:23.664688Z","shell.execute_reply":"2023-03-30T09:36:23.940402Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"972"},"metadata":{}}]},{"cell_type":"code","source":"spark.sql(\"\"\"SELECT * FROM transformed_customer_table\n          LIMIT 5\"\"\").show()","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:36:50.766065Z","iopub.execute_input":"2023-03-30T09:36:50.767332Z","iopub.status.idle":"2023-03-30T09:36:51.002120Z","shell.execute_reply.started":"2023-03-30T09:36:50.767282Z","shell.execute_reply":"2023-03-30T09:36:51.001111Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"+----------+------+---+------------+-------------+----------+--------------+----------+\n|CustomerID|Gender|Age|AnnualIncome|SpendingScore|Profession|WorkExperience|FamilySize|\n+----------+------+---+------------+-------------+----------+--------------+----------+\n|         2|  Male| 21|       35000|           81|  Engineer|             3|         3|\n|         4|Female| 23|       59000|           77|    Lawyer|             0|         2|\n|         6|Female| 22|       58000|           76|    Artist|             0|         2|\n|         8|Female| 23|       84000|           94|Healthcare|             1|         3|\n|        10|Female| 30|       98000|           72|    Artist|             1|         4|\n+----------+------+---+------------+-------------+----------+--------------+----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"spark.sql(\"\"\"SELECT * FROM transformed_customer_table\n          LIMIT 5\"\"\").write.csv(\"/kaggle/working/transformed.csv\",\n                               mode=\"overwrite\")","metadata":{"execution":{"iopub.status.busy":"2023-03-30T09:41:54.859640Z","iopub.execute_input":"2023-03-30T09:41:54.860018Z","iopub.status.idle":"2023-03-30T09:41:55.124000Z","shell.execute_reply.started":"2023-03-30T09:41:54.859987Z","shell.execute_reply":"2023-03-30T09:41:55.123076Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}