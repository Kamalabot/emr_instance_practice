{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install awswrangler","metadata":{"execution":{"iopub.status.busy":"2023-02-19T00:03:55.986915Z","iopub.execute_input":"2023-02-19T00:03:55.987414Z","iopub.status.idle":"2023-02-19T00:04:12.316650Z","shell.execute_reply.started":"2023-02-19T00:03:55.987306Z","shell.execute_reply":"2023-02-19T00:04:12.315389Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting awswrangler\n  Downloading awswrangler-2.19.0-py3-none-any.whl (267 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting redshift-connector<2.1.0,>=2.0.889\n  Downloading redshift_connector-2.0.910-py3-none-any.whl (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.1/112.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<=1.23.4,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.21.6)\nRequirement already satisfied: pyarrow<10.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (8.0.0)\nRequirement already satisfied: botocore<2.0.0,>=1.27.11 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.29.54)\nRequirement already satisfied: openpyxl<3.1.0,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (3.0.10)\nCollecting pg8000<2.0.0,>=1.20.0\n  Downloading pg8000-1.29.4-py3-none-any.whl (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jsonpath-ng<2.0.0,>=1.5.3\n  Downloading jsonpath_ng-1.5.3-py3-none-any.whl (29 kB)\nRequirement already satisfied: pandas!=1.5.0,<2.0.0,<=1.5.1,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.3.5)\nCollecting requests-aws4auth<2.0.0,>=1.1.1\n  Downloading requests_aws4auth-1.2.2-py2.py3-none-any.whl (24 kB)\nCollecting opensearch-py<3,>=1\n  Downloading opensearch_py-2.1.1-py2.py3-none-any.whl (220 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting gremlinpython<4.0.0,>=3.5.2\n  Downloading gremlinpython-3.6.2-py2.py3-none-any.whl (74 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting backoff<3.0.0,>=1.11.1\n  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\nCollecting pymysql<2.0.0,>=1.0.0\n  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: progressbar2<5.0.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (4.2.0)\nRequirement already satisfied: boto3<2.0.0,>=1.24.11 in /opt/conda/lib/python3.7/site-packages (from awswrangler) (1.26.54)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0.0,>=1.24.11->awswrangler) (0.6.0)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3<2.0.0,>=1.24.11->awswrangler) (1.0.1)\nRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<2.0.0,>=1.27.11->awswrangler) (1.26.14)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<2.0.0,>=1.27.11->awswrangler) (2.8.2)\nCollecting isodate<1.0.0,>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.5.5)\nCollecting aenum<4.0.0,>=1.4.5\n  Downloading aenum-3.1.11-py3-none-any.whl (131 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp<=3.8.1,>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from gremlinpython<4.0.0,>=3.5.2->awswrangler) (3.8.1)\nCollecting ply\n  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (1.15.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from jsonpath-ng<2.0.0,>=1.5.3->awswrangler) (5.1.1)\nRequirement already satisfied: et-xmlfile in /opt/conda/lib/python3.7/site-packages (from openpyxl<3.1.0,>=3.0.0->awswrangler) (1.1.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from opensearch-py<3,>=1->awswrangler) (2022.12.7)\nRequirement already satisfied: requests<3.0.0,>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from opensearch-py<3,>=1->awswrangler) (2.28.1)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas!=1.5.0,<2.0.0,<=1.5.1,>=1.2.0->awswrangler) (2022.1)\nCollecting scramp>=1.4.3\n  Downloading scramp-1.4.4-py3-none-any.whl (13 kB)\nRequirement already satisfied: importlib-metadata>=1.0 in /opt/conda/lib/python3.7/site-packages (from pg8000<2.0.0,>=1.20.0->awswrangler) (6.0.0)\nRequirement already satisfied: python-utils>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from progressbar2<5.0.0,>=4.0.0->awswrangler) (3.4.5)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (4.11.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (23.0)\nRequirement already satisfied: lxml>=4.6.5 in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (4.9.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from redshift-connector<2.1.0,>=2.0.889->awswrangler) (59.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (6.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.3.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (4.0.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (21.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (4.1.1)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (0.13.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (1.7.2)\nRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp<=3.8.1,>=3.8.0->gremlinpython<4.0.0,>=3.5.2->awswrangler) (2.1.0)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift-connector<2.1.0,>=2.0.889->awswrangler) (2.3.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=1.0->pg8000<2.0.0,>=1.20.0->awswrangler) (3.8.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py<3,>=1->awswrangler) (3.3)\nRequirement already satisfied: asn1crypto>=1.5.1 in /opt/conda/lib/python3.7/site-packages (from scramp>=1.4.3->pg8000<2.0.0,>=1.20.0->awswrangler) (1.5.1)\nInstalling collected packages: ply, aenum, pymysql, jsonpath-ng, isodate, backoff, scramp, requests-aws4auth, opensearch-py, pg8000, gremlinpython, redshift-connector, awswrangler\nSuccessfully installed aenum-3.1.11 awswrangler-2.19.0 backoff-2.2.1 gremlinpython-3.6.2 isodate-0.6.1 jsonpath-ng-1.5.3 opensearch-py-2.1.1 pg8000-1.29.4 ply-3.11 pymysql-1.0.2 redshift-connector-2.0.910 requests-aws4auth-1.2.2 scramp-1.4.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install nsepython","metadata":{"execution":{"iopub.status.busy":"2023-01-28T07:48:53.504822Z","iopub.execute_input":"2023-01-28T07:48:53.505253Z","iopub.status.idle":"2023-01-28T07:49:05.521070Z","shell.execute_reply.started":"2023-01-28T07:48:53.505211Z","shell.execute_reply":"2023-01-28T07:49:05.519455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import boto3\n#import awswrangler as wr\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-19T12:39:19.989091Z","iopub.execute_input":"2023-02-19T12:39:19.989835Z","iopub.status.idle":"2023-02-19T12:39:19.995514Z","shell.execute_reply.started":"2023-02-19T12:39:19.989794Z","shell.execute_reply":"2023-02-19T12:39:19.994402Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import nsepython as nse","metadata":{"execution":{"iopub.status.busy":"2023-02-19T00:04:47.202461Z","iopub.execute_input":"2023-02-19T00:04:47.203712Z","iopub.status.idle":"2023-02-19T00:04:47.308543Z","shell.execute_reply.started":"2023-02-19T00:04:47.203663Z","shell.execute_reply":"2023-02-19T00:04:47.306477Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1570206897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnsepython\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nsepython'"],"ename":"ModuleNotFoundError","evalue":"No module named 'nsepython'","output_type":"error"}]},{"cell_type":"code","source":"#load the AWS credentials and keep it ready\n\nimport configparser\n\nreader = configparser.ConfigParser()\nreader.read_file(open('/kaggle/input/private-set/calter.config'))\n\n\naws_reg = reader[\"AWS\"][\"REGION\"]\naws_key = reader[\"AWS\"][\"KEY\"]\naws_sec = reader[\"AWS\"][\"SECRET\"]\n\nmy_session = boto3.Session(aws_access_key_id=aws_key,aws_secret_access_key=aws_sec,\n                          region_name=aws_reg)\n\ns3_client = boto3.client('s3',region_name=aws_reg,aws_access_key_id=aws_key,\n                        aws_secret_access_key=aws_sec)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:39:27.648618Z","iopub.execute_input":"2023-02-19T12:39:27.649799Z","iopub.status.idle":"2023-02-19T12:39:28.252486Z","shell.execute_reply.started":"2023-02-19T12:39:27.649756Z","shell.execute_reply":"2023-02-19T12:39:28.251081Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"quick_client = boto3.client('quicksight',region_name=aws_reg,aws_access_key_id=aws_key,\n                        aws_secret_access_key=aws_sec)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:40:28.431368Z","iopub.execute_input":"2023-02-19T12:40:28.431861Z","iopub.status.idle":"2023-02-19T12:40:28.475879Z","shell.execute_reply.started":"2023-02-19T12:40:28.431824Z","shell.execute_reply":"2023-02-19T12:40:28.474984Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"response = quick_client.update_account_settings(\n    AwsAccountId='642924624251',\n    DefaultNamespace='default',\n    NotificationEmail='kamaljp@gmail.com',\n    TerminationProtectionEnabled=False\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:41:45.975088Z","iopub.execute_input":"2023-02-19T12:41:45.975571Z","iopub.status.idle":"2023-02-19T12:41:46.184250Z","shell.execute_reply.started":"2023-02-19T12:41:45.975532Z","shell.execute_reply":"2023-02-19T12:41:46.182968Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"response","metadata":{"execution":{"iopub.status.busy":"2023-02-19T12:41:48.118267Z","iopub.execute_input":"2023-02-19T12:41:48.118792Z","iopub.status.idle":"2023-02-19T12:41:48.128371Z","shell.execute_reply.started":"2023-02-19T12:41:48.118747Z","shell.execute_reply":"2023-02-19T12:41:48.126914Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'ResponseMetadata': {'RequestId': '150df652-00ff-4494-809f-7d77e8c5fca5',\n  'HTTPStatusCode': 200,\n  'HTTPHeaders': {'date': 'Sun, 19 Feb 2023 12:41:46 GMT',\n   'content-type': 'application/json',\n   'content-length': '396',\n   'connection': 'keep-alive',\n   'x-amzn-requestid': '150df652-00ff-4494-809f-7d77e8c5fca5'},\n  'RetryAttempts': 0},\n 'Status': 200,\n 'RequestId': '150df652-00ff-4494-809f-7d77e8c5fca5'}"},"metadata":{}}]},{"cell_type":"markdown","source":"There are many sources from which the data can come to Data Engineer or the Analyst. How to pull the data from these sources reliably? \n\n1 - List the sources and the designate a staging area. \n\n2 - Think of the source Type and the connection method.\n\n3 - Get the necessary credentials and register them for use.\n\n4 - Code the functions that pull the data into the staging.\n\n5 - Rinse and Repeat","metadata":{}},{"cell_type":"markdown","source":"### Lets Designate a Staging Area:\n\nStage @ AWS ==> s3://pipe-line-source\n\nPlace the string path in the variable","metadata":{}},{"cell_type":"code","source":"stage_path = \"pipe-line-source\"","metadata":{"execution":{"iopub.status.busy":"2023-01-28T11:55:38.179395Z","iopub.execute_input":"2023-01-28T11:55:38.179760Z","iopub.status.idle":"2023-01-28T11:55:38.185509Z","shell.execute_reply.started":"2023-01-28T11:55:38.179727Z","shell.execute_reply":"2023-01-28T11:55:38.184192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# There are two ways to list the contents of the bucket\n\n#Boto way: Note the bucket name is not having the prefix s3://\ntry:\n    s3_client.list_objects_v2(Bucket=stage_path)[\"Contents\"]\nexcept Exception as e:\n    print(\"The bucket must be empty.\")","metadata":{"execution":{"iopub.status.busy":"2023-01-28T11:55:48.296342Z","iopub.execute_input":"2023-01-28T11:55:48.296767Z","iopub.status.idle":"2023-01-28T11:55:48.670021Z","shell.execute_reply.started":"2023-01-28T11:55:48.296732Z","shell.execute_reply":"2023-01-28T11:55:48.669051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# listing the buckets\n\nwr.s3.list_buckets(boto3_session=my_session)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T11:55:55.015546Z","iopub.execute_input":"2023-01-28T11:55:55.016088Z","iopub.status.idle":"2023-01-28T11:55:55.507805Z","shell.execute_reply.started":"2023-01-28T11:55:55.016045Z","shell.execute_reply":"2023-01-28T11:55:55.506300Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#AWSWrangler way\n\nwr.s3.list_objects(path=f's3://'+stage_path,boto3_session=my_session)\n\n#AWSWrangler is quiet when it comes to empty buckets. ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T03:29:20.915995Z","iopub.execute_input":"2023-01-28T03:29:20.916419Z","iopub.status.idle":"2023-01-28T03:29:21.401927Z","shell.execute_reply.started":"2023-01-28T03:29:20.916388Z","shell.execute_reply":"2023-01-28T03:29:21.400850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"List of Sources : \n\nIn this notebook we will consider the following sources\n\n1) CSV or Json file from Kaggle dataset \n    \n    Use Kaggle notebook to load the dataset and then upload to S3\n    \n2) File of any type in the local file system:\n\n    The process will be same as the above steps used in Kaggle Notebook. \n\n3) Data needs to be pulled from a web API \n\n4) Tables from Local or Remote Relational Database needs to be dumped \n\n5) Tables inside Data Warehouses","metadata":{}},{"cell_type":"markdown","source":"### Loading files from Kaggle\n\na) Kaggle Notebook","metadata":{}},{"cell_type":"code","source":"%%sh\ncd /kaggle/input/\nls -R","metadata":{"execution":{"iopub.status.busy":"2023-01-29T09:45:48.721815Z","iopub.execute_input":"2023-01-29T09:45:48.722337Z","iopub.status.idle":"2023-01-29T09:45:48.762871Z","shell.execute_reply.started":"2023-01-29T09:45:48.722297Z","shell.execute_reply":"2023-01-29T09:45:48.761633Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":".:\nbosch-production-line-performance\notto-full-optimized-memory-footprint\nprivate-set\nworld-airports-and-airlines-datasets\nyelp-dataset\n\n./bosch-production-line-performance:\nsample_submission.csv.zip\ntest_categorical.csv.zip\ntest_date.csv.zip\ntest_numeric.csv.zip\ntrain_categorical.csv.zip\ntrain_date.csv.zip\ntrain_numeric.csv.zip\n\n./otto-full-optimized-memory-footprint:\nid2type.pkl\ntest.parquet\ntrain.parquet\ntype2id.pkl\n\n./private-set:\ncalter.config\n\n./world-airports-and-airlines-datasets:\nFinal_airlines\nairports_mod.dat\nroutes.dat\n\n./yelp-dataset:\nDataset_User_Agreement.pdf\nyelp_academic_dataset_business.json\nyelp_academic_dataset_checkin.json\nyelp_academic_dataset_review.json\nyelp_academic_dataset_tip.json\nyelp_academic_dataset_user.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# Get the file paths that needs to be uploaded\n\nimport os, json, glob\nfile_path = glob.glob(pathname=\"/kaggle/input/bosch-production-line-performance/*.zip\",\n                      recursive=True)\nfile_path","metadata":{"execution":{"iopub.status.busy":"2023-01-29T09:49:21.821975Z","iopub.execute_input":"2023-01-29T09:49:21.823200Z","iopub.status.idle":"2023-01-29T09:49:21.835544Z","shell.execute_reply.started":"2023-01-29T09:49:21.823137Z","shell.execute_reply":"2023-01-29T09:49:21.834117Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/bosch-production-line-performance/train_date.csv.zip',\n '/kaggle/input/bosch-production-line-performance/sample_submission.csv.zip',\n '/kaggle/input/bosch-production-line-performance/train_numeric.csv.zip',\n '/kaggle/input/bosch-production-line-performance/test_date.csv.zip',\n '/kaggle/input/bosch-production-line-performance/test_categorical.csv.zip',\n '/kaggle/input/bosch-production-line-performance/test_numeric.csv.zip',\n '/kaggle/input/bosch-production-line-performance/train_categorical.csv.zip']"},"metadata":{}}]},{"cell_type":"code","source":"#Pumping the files into S3\nfor fqp in file_path:\n    key = fqp.split('/')[4]\n    print(key)\n    wr.s3.upload(local_file=fqp,path=f's3://{stage_path}/{key}',\n                     boto3_session=my_session)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T03:45:58.167996Z","iopub.execute_input":"2023-01-28T03:45:58.169151Z","iopub.status.idle":"2023-01-28T03:47:09.654021Z","shell.execute_reply.started":"2023-01-28T03:45:58.169094Z","shell.execute_reply":"2023-01-28T03:47:09.652690Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validate the files are inside the bucket\nwr.s3.list_objects(path=f's3://{stage_path}',boto3_session=my_session)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T03:48:32.729568Z","iopub.execute_input":"2023-01-28T03:48:32.729963Z","iopub.status.idle":"2023-01-28T03:48:33.180358Z","shell.execute_reply.started":"2023-01-28T03:48:32.729933Z","shell.execute_reply":"2023-01-28T03:48:33.179083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Deleting the files in the bucket\nwr.s3.delete_objects(path=f's3://{stage_path}',boto3_session=my_session)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T03:49:49.670270Z","iopub.execute_input":"2023-01-28T03:49:49.670720Z","iopub.status.idle":"2023-01-28T03:49:50.586833Z","shell.execute_reply.started":"2023-01-28T03:49:49.670684Z","shell.execute_reply":"2023-01-28T03:49:50.585445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validate deletion\nwr.s3.list_objects(path=f's3://{stage_path}',boto3_session=my_session)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T03:50:07.360434Z","iopub.execute_input":"2023-01-28T03:50:07.360835Z","iopub.status.idle":"2023-01-28T03:50:07.749536Z","shell.execute_reply.started":"2023-01-28T03:50:07.360803Z","shell.execute_reply":"2023-01-28T03:50:07.748036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading files from Local Filesystem\n\nlocal_path = 'your/local/file/system/path'\n\nOnly change is the local_path name. Rest all remains same.\n\nWe will see how to put_objects using the Boto3 way...","metadata":{}},{"cell_type":"code","source":"%%sh\nuname -a","metadata":{"execution":{"iopub.status.busy":"2023-01-29T09:40:21.841712Z","iopub.execute_input":"2023-01-29T09:40:21.842907Z","iopub.status.idle":"2023-01-29T09:40:21.863224Z","shell.execute_reply.started":"2023-01-29T09:40:21.842858Z","shell.execute_reply":"2023-01-29T09:40:21.861608Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Linux 5c47bc14a9e1 5.15.65+ #1 SMP Sat Jan 21 10:12:05 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux\n","output_type":"stream"}]},{"cell_type":"code","source":"#uploading the objects using boto3 client. \n\n#Ensure the files that needs to uploaded are opened, read and uploaded. Else only the name\n#will be written\n\nfor fqp in file_path:\n    key = fqp.split('/')[4]\n    print(key)\n    with open(fqp,mode='rb') as temp_bytes:\n        s3_client.put_object(Body=temp_bytes,Bucket=stage_path,\n                            Key=key)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:06:50.267911Z","iopub.execute_input":"2023-01-28T04:06:50.268352Z","iopub.status.idle":"2023-01-28T04:07:12.689602Z","shell.execute_reply.started":"2023-01-28T04:06:50.268319Z","shell.execute_reply":"2023-01-28T04:07:12.688172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validate the buckets the boto3 way and get their keys\n#Prepare the Delete Key Objects\nfile_keys = [file['Key'] for file in s3_client.list_objects_v2(Bucket=stage_path)[\"Contents\"]]","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:14:58.513784Z","iopub.execute_input":"2023-01-28T04:14:58.514233Z","iopub.status.idle":"2023-01-28T04:14:59.000391Z","shell.execute_reply.started":"2023-01-28T04:14:58.514197Z","shell.execute_reply":"2023-01-28T04:14:58.999242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Validate the file_keys\nfile_keys","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:15:14.952225Z","iopub.execute_input":"2023-01-28T04:15:14.952643Z","iopub.status.idle":"2023-01-28T04:15:14.961426Z","shell.execute_reply.started":"2023-01-28T04:15:14.952613Z","shell.execute_reply":"2023-01-28T04:15:14.960011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Assemble the objects necessary for sending the deleting request\nfile_objects = []\nfor keys in file_keys:\n    temp = {\"Key\":keys}\n    file_objects.append(temp)\nfile_objects","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:19:04.421501Z","iopub.execute_input":"2023-01-28T04:19:04.421929Z","iopub.status.idle":"2023-01-28T04:19:04.430030Z","shell.execute_reply.started":"2023-01-28T04:19:04.421895Z","shell.execute_reply":"2023-01-28T04:19:04.428790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Delete the contents of the buckets Boto3 way\ns3_client.delete_objects(Bucket=stage_path,\n                         Delete={'Objects':file_objects,\n                                 'Quiet': True})","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:20:28.266369Z","iopub.execute_input":"2023-01-28T04:20:28.266784Z","iopub.status.idle":"2023-01-28T04:20:28.800294Z","shell.execute_reply.started":"2023-01-28T04:20:28.266752Z","shell.execute_reply":"2023-01-28T04:20:28.798917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data that needs to be pulled from API. \n\nThere are APIs that have web-site endpoints, and the other APIs that provide a wrapper around the weblink as Python Libraries. \n\nWe will see both of it in action in this section","metadata":{}},{"cell_type":"code","source":"all_fno_company = nse.fnolist()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:39:07.029748Z","iopub.execute_input":"2023-01-28T04:39:07.030170Z","iopub.status.idle":"2023-01-28T04:39:09.945989Z","shell.execute_reply.started":"2023-01-28T04:39:07.030138Z","shell.execute_reply":"2023-01-28T04:39:09.944585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bulk_deals = nse.get_bulkdeals()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:40:03.327812Z","iopub.execute_input":"2023-01-28T04:40:03.328299Z","iopub.status.idle":"2023-01-28T04:40:05.474197Z","shell.execute_reply.started":"2023-01-28T04:40:03.328262Z","shell.execute_reply":"2023-01-28T04:40:05.472834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"index_list = nse.nse_get_index_list()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:42:22.909182Z","iopub.execute_input":"2023-01-28T04:42:22.910331Z","iopub.status.idle":"2023-01-28T04:42:24.311524Z","shell.execute_reply.started":"2023-01-28T04:42:22.910290Z","shell.execute_reply":"2023-01-28T04:42:24.310249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nse.index_info(index_list[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:42:54.134058Z","iopub.execute_input":"2023-01-28T04:42:54.134931Z","iopub.status.idle":"2023-01-28T04:42:56.327084Z","shell.execute_reply.started":"2023-01-28T04:42:54.134887Z","shell.execute_reply":"2023-01-28T04:42:56.325761Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holidays = nse.nse_holidays()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:47:20.179238Z","iopub.execute_input":"2023-01-28T04:47:20.179691Z","iopub.status.idle":"2023-01-28T04:47:20.468140Z","shell.execute_reply.started":"2023-01-28T04:47:20.179656Z","shell.execute_reply":"2023-01-28T04:47:20.467034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"company_info = nse.nse_eq(\"DIXON\")","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:01:09.658295Z","iopub.execute_input":"2023-01-28T05:01:09.658736Z","iopub.status.idle":"2023-01-28T05:01:12.046251Z","shell.execute_reply.started":"2023-01-28T05:01:09.658701Z","shell.execute_reply":"2023-01-28T05:01:12.044928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"company_info.keys()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:01:21.846730Z","iopub.execute_input":"2023-01-28T05:01:21.847169Z","iopub.status.idle":"2023-01-28T05:01:21.855072Z","shell.execute_reply.started":"2023-01-28T05:01:21.847131Z","shell.execute_reply":"2023-01-28T05:01:21.853770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"equity_data = nse.equity_history(\"DIXON\",\"EQ\",\"01-12-2022\",\"25-01-2023\")","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:54:04.569339Z","iopub.execute_input":"2023-01-28T04:54:04.569780Z","iopub.status.idle":"2023-01-28T04:54:05.205891Z","shell.execute_reply.started":"2023-01-28T04:54:04.569749Z","shell.execute_reply":"2023-01-28T04:54:05.204802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"equity_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T04:54:12.063689Z","iopub.execute_input":"2023-01-28T04:54:12.064159Z","iopub.status.idle":"2023-01-28T04:54:12.099236Z","shell.execute_reply.started":"2023-01-28T04:54:12.064122Z","shell.execute_reply":"2023-01-28T04:54:12.097701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"equity_data.columns","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:00:42.627848Z","iopub.execute_input":"2023-01-28T05:00:42.628329Z","iopub.status.idle":"2023-01-28T05:00:42.637559Z","shell.execute_reply.started":"2023-01-28T05:00:42.628293Z","shell.execute_reply":"2023-01-28T05:00:42.636168Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on exploring the nse library, the equity history provides a whole lot of information for each equity. The get_advances_declines method provides the list of equities that have advanced and declined recently.\n\nIdea 1: Take the list of Symbols in Advances & Declines, get their history for past 3 months, and store the data as parquets in Staging Area\n\nIdea 2: Nse also provides the details of each equity in a lot more detail. This detail can be collected as seperate jsons and stored in Staging Area\n\nIdea 3: Library provides access to the fnolist and the method option scraper provides the Option chain for the options, which can also be scraped...  ","metadata":{}},{"cell_type":"code","source":"nse.nse_fiidii()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:03:11.349386Z","iopub.execute_input":"2023-01-28T05:03:11.349822Z","iopub.status.idle":"2023-01-28T05:03:13.477093Z","shell.execute_reply.started":"2023-01-28T05:03:11.349786Z","shell.execute_reply":"2023-01-28T05:03:13.476206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fnoList = nse.fnolist()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:05:51.296029Z","iopub.execute_input":"2023-01-28T05:05:51.296474Z","iopub.status.idle":"2023-01-28T05:05:51.637447Z","shell.execute_reply.started":"2023-01-28T05:05:51.296439Z","shell.execute_reply":"2023-01-28T05:05:51.636121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nse.nse_optionchain_scrapper(fnoList[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:06:00.133403Z","iopub.execute_input":"2023-01-28T05:06:00.133794Z","iopub.status.idle":"2023-01-28T05:06:03.447732Z","shell.execute_reply.started":"2023-01-28T05:06:00.133763Z","shell.execute_reply":"2023-01-28T05:06:03.446461Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### I will be coding only the 1st Idea here\n\n1) Get the list of companies that have advanced and declined\n\n2) The equity history is required for last 3 months that is startDate = '01-11-2022' to endDate = '27-11-2023'\n\n3) Store the pandas dataframe as parquets using the awswrangler, into the s3 bucket","metadata":{}},{"cell_type":"code","source":"advances_declines = nse.nse_get_advances_declines()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:46:43.096458Z","iopub.execute_input":"2023-01-28T05:46:43.096841Z","iopub.status.idle":"2023-01-28T05:46:46.720982Z","shell.execute_reply.started":"2023-01-28T05:46:43.096811Z","shell.execute_reply":"2023-01-28T05:46:46.719485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"companies_adv_declines = list(advances_declines[\"symbol\"])","metadata":{"execution":{"iopub.status.busy":"2023-01-28T05:48:30.662420Z","iopub.execute_input":"2023-01-28T05:48:30.663487Z","iopub.status.idle":"2023-01-28T05:48:30.668294Z","shell.execute_reply.started":"2023-01-28T05:48:30.663441Z","shell.execute_reply":"2023-01-28T05:48:30.667252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Developing the Function spec\n\n1) Parameters are : Symbol, Start_date, End_date, s3_bucket_fql\n\n2) Methods used : nse.equity_history(), awswrangler.s3.to_parquet()","metadata":{}},{"cell_type":"code","source":"def store_stock_data(symbol:str,start_date:str,\n                     end_date:str, s3_bucket_fql:str,\n                    boto_session):\n    \"\"\"\n    Function writes the data of the symbol given to the designated S3_bucket path \n    as parquet file. The bucket location must be fully qualified including the s3:// \n    header like this 's3://your_bucket/equity_parquets/'. The date must be in \"01-12-2022\" format. Only Equity data will be \n    fetched.\n    \"\"\"\n    equity_dataframe = nse.equity_history(symbol,\"EQ\",start_date,end_date)\n    \n    print(equity_dataframe.head(2))\n    \n    wr.s3.to_parquet(df=equity_data,path=s3_bucket_fql,\n                     boto3_session=boto_session,\n                dataset=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T06:43:56.386981Z","iopub.execute_input":"2023-01-28T06:43:56.388297Z","iopub.status.idle":"2023-01-28T06:43:56.395736Z","shell.execute_reply.started":"2023-01-28T06:43:56.388254Z","shell.execute_reply":"2023-01-28T06:43:56.394359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s3_bucket_fql = 's3://pipe-line-source/equity_parquets'\nbegin_date = '01-11-2022'\nto_date = '27-01-2023'","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:43:37.814546Z","iopub.execute_input":"2023-01-28T12:43:37.814975Z","iopub.status.idle":"2023-01-28T12:43:37.820481Z","shell.execute_reply.started":"2023-01-28T12:43:37.814940Z","shell.execute_reply":"2023-01-28T12:43:37.818971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"companies_adv_declines[2:5]","metadata":{"execution":{"iopub.status.busy":"2023-01-28T06:44:07.322253Z","iopub.execute_input":"2023-01-28T06:44:07.322795Z","iopub.status.idle":"2023-01-28T06:44:07.331798Z","shell.execute_reply.started":"2023-01-28T06:44:07.322746Z","shell.execute_reply":"2023-01-28T06:44:07.330161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for sym in companies_adv_declines[2:5]:\n   store_stock_data(symbol=sym, start_date=begin_date,end_date=to_date,\n                   boto_session=my_session,s3_bucket_fql=s3_bucket_fql) ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T06:44:16.556373Z","iopub.execute_input":"2023-01-28T06:44:16.556794Z","iopub.status.idle":"2023-01-28T06:44:20.805919Z","shell.execute_reply.started":"2023-01-28T06:44:16.556761Z","shell.execute_reply":"2023-01-28T06:44:20.804610Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data that needs to be pulled from weblink. \n\nThere are APIs that have web-site endpoints, some time require additional authentication string that needs to be sent along with the requests. We will be using Python's requests library\n\nThere are many APIs available. I want to take a look at any of the news paper APIs.\nAmong them Ycombinator for technology, newsapi seems to be very helpful in terms of data provided. \n\nhttps://hackernews.api-docs.io/v0/overview/introduction\n\nhttps://newsapi.org/docs/get-started\n\nhttps://developers.kite.trade/apps\n\nI am checking Zerodha dev account now.","metadata":{}},{"cell_type":"code","source":"import requests\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-01-28T11:57:10.108904Z","iopub.execute_input":"2023-01-28T11:57:10.109280Z","iopub.status.idle":"2023-01-28T11:57:10.114408Z","shell.execute_reply.started":"2023-01-28T11:57:10.109249Z","shell.execute_reply":"2023-01-28T11:57:10.113221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getnews_df(api_url):\n    \"\"\"The function returns the total articles, and array of json objects.\n    Requires json, requests and pandas library\"\"\"\n    rawRequest = requests.request(\"GET\",url=api_url)\n    jsonData = rawRequest.json()\n    if jsonData['status'] == 'ok':\n        articleDF = pd.DataFrame(jsonData['articles'])\n        return articleDF\n    else:\n        return jsonData","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:49:05.344800Z","iopub.execute_input":"2023-01-28T08:49:05.345245Z","iopub.status.idle":"2023-01-28T08:49:05.352932Z","shell.execute_reply.started":"2023-01-28T08:49:05.345208Z","shell.execute_reply":"2023-01-28T08:49:05.351670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ukraine_df = getnews_df(api_url=f'https://newsapi.org/v2/everything?q=Ukraine&from=2022-12-29&to=2023-01-27&sortBy=popularity&apiKey={myAPI}')","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:49:07.495357Z","iopub.execute_input":"2023-01-28T08:49:07.495786Z","iopub.status.idle":"2023-01-28T08:49:07.599832Z","shell.execute_reply.started":"2023-01-28T08:49:07.495747Z","shell.execute_reply":"2023-01-28T08:49:07.597940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_news_s3(search_str:str,start_date:str,\n                     end_date:str, s3_bucket_fql:str,\n                    boto_session, api_key):\n    \"\"\"The date must be in the 2023-01-27 format. \n    Newsapi key needs to be supplied for getting the data written to S3.\n    Provide a valid S3 bucket in the format s3://your_bucket/news_parquets/\"\"\"\n    #Build the url\n    buildAPI =f'https://newsapi.org/v2/everything?q={search_str}&from={start_date}&to={end_date}&sortBy=popularity&apiKey={myAPI}'\n    #Get raw data\n    getRaw = requests.request(\"GET\",url = buildAPI)\n    #Convert data to json\n    getJson = getRaw.json()\n    #Check if json contains required data\n    if getJson['status'] == \"ok\":\n        #Inform the user\n        print(f'Recieved {getJson[\"totalResults\"]}News articles. Sending to S3')\n        #Convert to dataframe\n        articleDF = pd.DataFrame(getJson['articles'])\n        #Wrap the s3 write in try except block \n        try:\n            #write to S3\n            wr.s3.to_parquet(df=articleDF,path=s3_bucket_fql,\n                         boto3_session=boto_session,\n                    dataset=True)\n        #Triggering Exception\n        except Exception as e:\n            \n            print(f'There is an error.{e}')\n        #inform completion\n        print(\"Sent data to S3\")","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:02:01.116676Z","iopub.execute_input":"2023-01-28T09:02:01.117106Z","iopub.status.idle":"2023-01-28T09:02:01.126208Z","shell.execute_reply.started":"2023-01-28T09:02:01.117073Z","shell.execute_reply":"2023-01-28T09:02:01.124773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"search_string = 'United States'\nstart='2022-12-29'\nend = '2023-01-15'\ns3_endpoint = 's3://pipe-line-source/news_parquets'\nmyAPI = '401c52566bb34b72b44bf08e738ce953'","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:04:32.885560Z","iopub.execute_input":"2023-01-28T09:04:32.885996Z","iopub.status.idle":"2023-01-28T09:04:32.892748Z","shell.execute_reply.started":"2023-01-28T09:04:32.885940Z","shell.execute_reply":"2023-01-28T09:04:32.891110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"write_news_s3(search_str=search_string,start_date=start,\n             end_date=end,s3_bucket_fql=s3_endpoint,\n                api_key=myAPI,boto_session=my_session)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T09:05:56.015880Z","iopub.execute_input":"2023-01-28T09:05:56.016552Z","iopub.status.idle":"2023-01-28T09:05:56.964058Z","shell.execute_reply.started":"2023-01-28T09:05:56.016505Z","shell.execute_reply":"2023-01-28T09:05:56.962630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Connecting to RDS through Psycopg2 library and then writing to S3\n\nYou might be wondering why the AWS's own services Athena and RDS doesn't talk with each other? That is because, Athena is BigData cluster while RDS instance is a regular database instance. \n\nIn order make them talk, connections needs to be invoked through Lambda or through Glue Job. Both of which are chargeable. The work around ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T08:40:15.780711Z","iopub.execute_input":"2023-01-28T08:40:15.781181Z","iopub.status.idle":"2023-01-28T08:40:15.800931Z","shell.execute_reply.started":"2023-01-28T08:40:15.781143Z","shell.execute_reply":"2023-01-28T08:40:15.799852Z"}}},{"cell_type":"code","source":"!pip install psycopg2-binary public-ip","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:11:14.104656Z","iopub.execute_input":"2023-01-28T12:11:14.105079Z","iopub.status.idle":"2023-01-28T12:11:26.442763Z","shell.execute_reply.started":"2023-01-28T12:11:14.105044Z","shell.execute_reply":"2023-01-28T12:11:26.441615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import psycopg2\nimport public_ip","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:11:37.303960Z","iopub.execute_input":"2023-01-28T12:11:37.304384Z","iopub.status.idle":"2023-01-28T12:11:37.327765Z","shell.execute_reply.started":"2023-01-28T12:11:37.304349Z","shell.execute_reply":"2023-01-28T12:11:37.326541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#get the database credentials\n\nreader = configparser.ConfigParser()\nreader.read_file(open('/kaggle/input/private-set/calter.config'))\n\n\ndatabaseHost = reader[\"POSTGRES\"][\"PG_HOST\"]\ndb_pass = reader[\"POSTGRES\"][\"PG_PASS\"]\ndb_uname = reader[\"POSTGRES\"][\"PG_UNAME\"]\ndb_name = reader[\"POSTGRES\"][\"PG_DB\"]\ndb_port = reader[\"POSTGRES\"][\"PG_PORT\"]","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:14:15.610253Z","iopub.execute_input":"2023-01-28T12:14:15.610675Z","iopub.status.idle":"2023-01-28T12:14:15.619192Z","shell.execute_reply.started":"2023-01-28T12:14:15.610644Z","shell.execute_reply":"2023-01-28T12:14:15.618007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### since the RDS is behind the firewall need the ip \nnew_ip = public_ip.get()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:34:46.745230Z","iopub.execute_input":"2023-01-28T12:34:46.745637Z","iopub.status.idle":"2023-01-28T12:34:47.387245Z","shell.execute_reply.started":"2023-01-28T12:34:46.745604Z","shell.execute_reply":"2023-01-28T12:34:47.386065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Need to set the current Kaggle instance IP to the AWS Security Group\ndef change_local_ingress(new_ip):\n    #Initiate the new ec2 client\n    ec2_client = boto3.client('ec2',region_name=aws_reg,aws_access_key_id=aws_key,\n                           aws_secret_access_key=aws_sec)\n    #assign the security group\n    sec_grp = 'sg-060ab746844bf1595'\n    #get the ip from the function argument\n    newPermissions=[\n          {\n              'FromPort': 0,\n              'IpProtocol': 'tcp',\n              'IpRanges': [\n                  {\n                      'CidrIp': f'{new_ip}/32',\n                  },\n              ],\n              'ToPort': 50153,\n          },\n\n      ]\n    #Authorized the ingress\n    ec2_client.authorize_security_group_ingress(GroupId=sec_grp,IpPermissions=newPermissions)\n    ","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:35:29.134748Z","iopub.execute_input":"2023-01-28T12:35:29.135847Z","iopub.status.idle":"2023-01-28T12:35:29.143068Z","shell.execute_reply.started":"2023-01-28T12:35:29.135766Z","shell.execute_reply":"2023-01-28T12:35:29.141688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This will push the authorisation for the ingress \nchange_local_ingress(new_ip=new_ip)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:35:31.569099Z","iopub.execute_input":"2023-01-28T12:35:31.569479Z","iopub.status.idle":"2023-01-28T12:35:32.438702Z","shell.execute_reply.started":"2023-01-28T12:35:31.569450Z","shell.execute_reply":"2023-01-28T12:35:32.437701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to get the dataframe from the required query\ndef query_database_rds(query):\n    \"\"\"Function establishes the connection and then \n    uses the query to get the dataframe out of the database table.\"\"\"\n    #Establish connection, and provide autocommit option to true\n    try:\n        conn = psycopg2.connect(host=databaseHost,\n                            dbname=db_name,user=db_uname,\n                            password=db_pass,port=db_port)\n    \n        conn.set_session(autocommit=True)\n        \n        cur = conn.cursor()\n        \n    except Exception as e:\n        print(e)\n    \n    #Query the table \n    \n    cur.execute(query)\n    \n    #get the data into templist\n    \n    tempList = cur.fetchall()\n    \n    #feed the templist into pandas.DataFrame and return\n    \n    return pd.DataFrame(tempList)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:41:02.759065Z","iopub.execute_input":"2023-01-28T12:41:02.759504Z","iopub.status.idle":"2023-01-28T12:41:02.767961Z","shell.execute_reply.started":"2023-01-28T12:41:02.759471Z","shell.execute_reply":"2023-01-28T12:41:02.766612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"query_yt = \"\"\"SELECT * FROM yt_csv LIMIT 5\"\"\"\nresult_dataframe = query_database_rds(query=query_yt)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:41:38.114736Z","iopub.execute_input":"2023-01-28T12:41:38.115134Z","iopub.status.idle":"2023-01-28T12:41:38.777894Z","shell.execute_reply.started":"2023-01-28T12:41:38.115104Z","shell.execute_reply":"2023-01-28T12:41:38.776689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_dataframe.head()","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:44:37.759393Z","iopub.execute_input":"2023-01-28T12:44:37.762107Z","iopub.status.idle":"2023-01-28T12:44:37.786099Z","shell.execute_reply.started":"2023-01-28T12:44:37.762065Z","shell.execute_reply":"2023-01-28T12:44:37.785012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wr.s3.to_csv(df=result_dataframe,path=\"s3://pipe-line-source/\",\n                         boto3_session=my_session,\n                    dataset=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-28T12:46:14.580143Z","iopub.execute_input":"2023-01-28T12:46:14.580526Z","iopub.status.idle":"2023-01-28T12:46:15.150074Z","shell.execute_reply.started":"2023-01-28T12:46:14.580495Z","shell.execute_reply":"2023-01-28T12:46:15.148864Z"},"trusted":true},"execution_count":null,"outputs":[]}]}